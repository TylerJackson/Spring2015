CSE 7320 Artificial Intelligence Lecture Notes


-------------------------------------------------------

Artificial Intelligence Lecture 1 

mee-hah-ella

mihaela@smu.edu
iridon.mihaela@gmail.com

email her with
Name
Graduate/Undergraduate
Education/background/currentresearchtopic
programming skills
data structures, algorithms, OOP?
any particular interests in AI?
why are you taking this course?

A.I. 
What machines think?
robots?
playing chess?
searching for information?
the movie A.I.?
alan turing automata transcendence
machines that read and speak
language translations
computer animation
learning

nanorobotics
-cure diseases in the blood

chess playing robot beat chess grandmaster Garry Kasparov in May 1997

swarming flocking steering technology
lord of the rings 
matrix

Automatic Speech Recognition (ARS)
Raymond Kertzwild

Turing Test
-Ultimate AI challenge

AI
-math
-philosophy
-cybernetics
-economics
-psycology
-neuroscience
-economics
-physics
-linguistics

superintelligence


What is AI
-the field of research that attempts to emulate human intelligence in a machine

Artificial->machine
Intelligence->?
	-learning
	-reasoning
	-ability to manipulate symbols

Dissecting AI
-thinking---		
			humanly and rationally
-acting-----

rationality
-doing the right thing knowing what I know

intelligent system
-system that perceives its environment and takes actions which maximizes its chance of success

Turing Test approach
-can machines think? can they behave intelligently?
-use a human interrogator to determine if it is a human or a machine
-make it 5 minutes without interrogater being able to tell
Requirements
-NLP (english communication)
-knowledge representation
-automated reasoning (to answer questions)
-machine learning(adapt, detect patterns)

Total Turing Test:(video-perception)
	-computer vision (perceive objects)
	-robotics (manipulate objects, move)

problem with turing test:
-not reproducible, constructive, or amenable to mathematical analysis

Turing test extra credit
-convince the examiner he is a machine

--------------------------------------------------------------------------------------------------------------

Artificial Intelligence Lecture 2 Notes

Thinking Humanly: Cognitive Modeling Approach
-1960s "cognitive revolution": information-processing psychology replcaed prevailing belief of behaviorism
-requires scientific theories of internal activities of the brain
	-what level of abstraction? "knowledge" or "circuits"?
	-how to validate?
		-requires:
		-1.) predicting and testing behavior of human subjects (top down) or
		-2.) Direct identification from neurological data (bottom up)
-both approaches (roughly, Cognitive Science (McCarthy) and Cognitive Neuroscience) are now distinct from AI
-both share with AI the following characteristic:
	-the available theories do not explain (or produce) anything resembling human-level general intelligence

Thinking Rationally: The Laws of Thought
-Normative (or prescriptive) rather than descriptive
-Aristotle: What are correct argument/thought processes?
	-fueled by logic
-direct line through mathematics and philosophy to modern AI
-Problems:
	1.) Not all intelligent behavior is mediated by logical deliberation
	2.) What is the purpose of thinking? What thoughts should I ahve out of all the thoughts (logical or otherwise) that I could have?

Acting Rationally: the Rational Agent approach
-rational behavior: doing the 'right' thing
-the right thing: that which is expected to maximize goal achievement, given the available information
-Doesn't necessarily involve thinking - e.g. blinking reflex - but thinking should be in the service of rational action
-Aristotle (Nicomachean Ethics):
	-every art and every inquiry, and similarly action and pursuit, is thought to aim at some good

Rational Agents
-an agent is an entity that perceives and acts 
-this course is about designing rational agents
-abstractly, an agent is a function from percept history to actions:
	f: P* -> A
-for any given class of environments and tasks, we seek the agent (or class of agents) with the best performance
-Caveat: computational limitations make perfect rationality unachievable
	-> design best program for given machine resources

History of AI
-been ups and downs

AI Applications
-AI effect
	-as soon as AI successfully solves a problem, the problem is no longer a part of AI
	-Deep Blue ('97)
		-intelligent or use brute force computation
	-AI s whatever hasn't been done yet
-Roomba 
-IVR: TTS, ASR
		-> text to speech, speech recognition

State of the Art
-autonomous planning and scheduling:
	-NASA's Remote Agent
-Game Playing:
	-IBM's Deep Blue and Watson
-autonomous control:
	-Google Self-Driving Car
	-ALVINN computer vision system (car steering)
-medical diagnosis
	-expert physician level in some areas of medicine
-logistic planning
	-DART (transportation, Persian Gulf crisis '91)
-Robotics:
	-HipNav (microsurgery)
-Language Understanding and problem solving:
	-PROVERB

the Universality of AI
-knowledge-based systems
-expert systems
-pattern recognition
-automatic learning and reasoning
-natural-language processing/understanding (NLP)
-robotics, computer vision
-...
	-AI systematizes and automates intellectual tasks and is therefore potentially relevant to any sphere of human intellectual activity

at the forefront of AI
-Raymond Kurzweil
-Noam Chomsky
	-professor of linguistics at MIT
-Roger Shank
	-former professor at Yale (director of Yale AI project)
-Austin Tate
-David Touretzky
-Judea Pearl

Go over slide 28 lecture 2

Reading Assignment
-Chapter 1 from textbook
-Raymond Kurzweil: (online)
	-the Age of Intelligent Machines, Chapter One: The Roots of Artificial Intelligence:
	-www.kurzweilai.net/the-age-of-intelligent-machines-chapter-one-the-roots-of-artificial-intelligence
Optional
-Daniel Dennett: (online @ kurzwelai.net)
	-The age of intelligent machines: Can machines think?
		-http://www.kurzweilai.net/the-age-of-intelligent-machines-can-machines-think-3
-http://www.kurzweilai.net/ebooks/the-age-of-intelligent-machines

Additional Topics: Recursion
-Computational Thinking
	-Jeanette Wing- Carnegie Mellon
	-Computational thinking: CT
		-thinking like a computer scientist
		-thinking recursively and algorithmically
		-a fundamental skill used by everyone by mid 21st century, enabled by computing and computers
		-abstraction and modeling of data
			-multiple layers (relationships)
			-analysis and organization
		-automation
			-mechanizing the abstraction layers and the relationship among them
			-an algorithm, a Turing machine, a tangible device, a software system -or the human brain

More about CT's concerns
-how difficult is this problem and how best can I solve it?
	-theoretical computer science gives precise meaning to these and related questions and their answers
-C.T. is thinking recursively
-C.T. is reformulating a seemingly difficult problem into one which we know how to solve (Reduction, embedding, transformation, simulation)
-C.T. is choosing an appropriate representation or modeling the relevant aspects of a problem to make it tractable
-C.T. is interpreting code as data and data as code
-C.T. is using abstraction and decomposition in tackling a large complex task
-C.T. is judging a system's design for its simplicity and elegance
-C.T. is prevention and detection and recovery from worst-case scenarios through redundancy, damage containment, and error correction
-C.T. is taking an approach to solving problems, designing/modeling systems, and understanding human behavior that draws on concepts fundamental to computer science

Linked Data Structures and Recursion
-why study Linked DS and Recursion together?
	-define soemthing in terms of what is being defined
-recursive method/function/subroutine:
	-in its implementation, it is calling itself directly or indirectly
-linked data structure
	-an object contains a link to another object that belongs to the same class (data type)
		-the class is used in its own definition

Recursion
-Recursive definition
	-uses the concept/thing that is being defined as part of the definition
		-A "directory" is a logical component/unit of the file-system (managed on the disk by the OS) that contains files, other directories, (or is empty).
		-a "set" is a collection of elements, which can be other sets
		-the "prime" numbers can be defined as consisting of:
			-2, the smallest prime
			-each positive integer which is not evenly divisible by any of the primes smaller than itself
		-"GNU" = a recursive acronym for "GNU's Not Unix"

Recursive vs. Circular Definition
-recursion has base case
-circular definition has no base case

Greedy Algorithms
-making the best choice (locally) at each step
-iterative approach to reducing the problem
	-TSP: at each step visit the nearest unvisited city
-Notable examples: 
	-minimum spanning trees (Kruskal, Prim)
	-shortest path (Dijkstra)
-problem with Greedy apprach:
	-most of the time will fail to find the globally optimal solution, b.c. they usually do not operate exhaustively on all the data

Dynamic Programming
-for problems with overlapping sub-problems and omptimal substructures
	-mathematical programming == optimization
	-programming = finding an acceptable plan of action (scheduling of events)
-at each step make decisions based on all the decisions made in the previous stage
	-memorize states/steps/solutions to sub-problems
-may reconsider the previous choices (path to a solution)
-Examples:
	-shortest path
	-fibonacci sequence

Divide and Conquer -> recursion
-recursively breaking down a problem into two or more sub-problems of the same (or related) type, until these become simple enough to be solved directly 
-efficient algorithm implementation:
	-E.g. sorting (quick sort, merge sort)
	-suitable for parallel execution/processing
-powerful tool for solving conceptually difficult problems
	-tower of Hanoi puzzle
-disadvantage
	-recursion is slow
		-overhead of repeated subroutine calls
		-storing intermediate results on the stack

Recursion simplifed via examples
-2 parts
	-solve easy problems in 1 step (base case)
	-divide hard problems into smaller problems, and then solve smaller problems

-How do you study a text book?
A (1) Read the book on day 1, and (2) read it again 
	each day of the semester
B (1) if you have reached the end of the book you are 
	done, else (2) study one page, then study the rest of the book
C (1) Divide the book in 2, and (2) study each half
D (1) Cram all the pages in one horrible session, and 
	(2) forget everything the next night

B is recursive

How can you drunk an entire keg of root beer?
A (1) take one swallow, then (2) take another swallow
B (1) If the keg is empty do nothing, otherwise (2) 
	take one swaller, then drink the rest of the keg
C (1) take one enormous gulp, and (2) wish you hadn't
D (1) drink one key, and (2) drink another keg

B is recursive

Triangular #s T_n = Sum k = 1 + 2 + 3+..+ (n-2)+(n-1) + n = n(n+1)/2 = (n^2 + n)/2 

T(1) = 1
T(2) = 1 + 2 = T(1) + 2 = 3
T(3) = 1 + 2 + 3 = T(2) + 3 = 6
T(N) - N + T(N-1)

c#
-static class means not storing a state at the class level
-slide 16 lecture 3 Recursion & Iteration:Triangular #s

Other Recursive examples
-factorial
-A^B
-Fibonacci series
-reverse a list or a string
-count elements in a list (length of the list)
-find the MAX/MIN value in a list/array
-traverse a linked list/tree
-add the numbers in a list
-return the nth element in a list
-find the depth of a tree
-permutations
-binomial coefficients

LISP Concepts
-download LISP 

Programming Paradigms
-OOP (C#,C++,Java)-> objects
-Procedural (C, Pascal) -> procedures
-Logic Programming (Prolog) -> predicates
-Functional (LISP, ML, Haskell) -> functions

-OOP & Procedural -> imperative
	-"how to"
	-Goal = implicit, Algorithm= explicit
-Functional and Logic -> declarative
	-"what is"
	-Goal = explicit, Algorithm = implicit

Programming Paradigm
-treats computation = evaluation of mathematical functions; avoids state and mutable data
-contrast to imperative programming style
	-statements that change a program state
-Lisp, ML, Scheme, Mathematica
-Lambda Calculus
	-model for functional programming
-functions that accept other functions as parameters

About LISP = LISt Processing Language
-second-oldest high-level programming language
-Dialects
	-Common LISP; Scheme
-Data structures 
	-linked lists (incl. source code)
-GNU CLISP
	-common LISP:
		-high level, general-purpose, object-oriented, dynamic, functional programming language
	-CLISP
		-an ANSI Common Lisp implementation
		-current version 2.49
		-download from www.clisp.org

LISP fundamental data structures
-numbers
	-integers
	-floating points
	-ratios
-symbols
-lists

Numbers
	-integer, rational, real, and complex
		5
		-24
		PI
		3/4
		1.722e-15
		#c(1.722e-15 0.75)
	-Integer: a sequence of digits "0" through "9" optionally preceded by a plus or minus sign
	-predicate functions in lisp NUMBERP, ODDP, EVENP, ZEROP
		-return true or false

Symbols
	-any sequence of letters, digits, and permissible special characters that is not a number
	FOUR -> symbol
	4 -> integer
	+4 -> integer
	+ -> symbol
	R2D2 -> symbol
	7-11 -> symbol

True is T
False is Nil

Primitive functions built into Common LISP
-NOT predicate
	-reutrns NIL for every input except NIL
-Predicates 
	-input anything
	-output:T/Nil
-truth functions
	-input T/Nil
	-output: T/Nil

Errors
-wrong input type
-wrong number of arguments
-division by zero

Lists
-lists can represent anything
	-sets
	-tables
	-graphs
	-english sentences
	-functions
-2 forms
	-printed form / representation
	-internal form

List examples and Representations
-list = chain of cons cells
-a cons cell has 2 pointers
-1 to data
-1 to next element in list
-last points to nil instead of next element

Nested Lists
-nested lists
-well-formed = properly balanced parentheses

Lists can be compared using =
-compares if elements are equal

CAR and CDR
-primitive operations on linked lists
-Cons cells
	-composed of 2 pointers
	-in first implementation has 4 parts, 2 of which were
		-ADDRESS part (15-bit)
		-DECREMENT part (15-bit)
-CAR: contents of Address register
-CDR: Contents of Decrement Register
-May be combined in various ways
	-CADR, CAAR, CDDR, CADAR, C{[A|D]}R
	-CAR & CDR applied to NIL = NIL

CAR/CDR exercise
	L = ((A B)(C D)(E F))
	-length = 3
	-first element is list not atom
	-CAR returns first element
	-CDR everything but first element of List
	-read letters from right to left of function
	function 		result
	CAR 			(A B)
	CDR 			((C D)(E F))
	CDDR			((E F))			-CDR of CDR
	CADR 			(C D)			-CAR of CDR
	CDAR 			 				-CDR of CAR
	CADAR			B 				-CAR of CDR of CAR
	CDDAR			

Proper list
Dotted List
-Dotted pair 

Eval Notation
-Unifying the notation for functinos and ata 
	-f(x,y): f(x,g(y))
-in LISP, functions are data
-EVAL:
	-Evaluate Lisp expressions to compute the result 
	-Expression: function + input arguments
	-(+ 2 3) -> 5 (EVAL notation)
	-(oddp (+ 2 3)) -> T
	-(/(* 2 11)(+ 1 6)) -> 22/7

EVAL rules
-numbers, T, NIL evaluate to themselves
-Lists:
	-the first element of the list specifies a function to be called. The remaining elements specify arguments to the function. The function is called on the evaluated arguments
-Symbols
	-evaluate to the value of the variable it refers to
-Quoted objects
	-evaluate to the object itself without the quote

form
-what you type to the LISP interpreter
-LISP interpreter does the following
	-reads a form
	-evaluates the form read
	-prints the result
	-READ-EVAL-PRINT loop
-Form:
	-ATOM (a symbol, an integer, a string)
		-evaluated immediately
	-LIST
		-first element = a function; evaluates args first

-LISP saves its most recent 3 results
>* gets last result
>** gets second to last result

Numeric Functions
-sqrt,abs, mod, round, expt, sin,cos,tan...

List Construction functions
-Cons
	-(cons first list)
	-(cons 2 '(5 7)) -> (2 5 7)
	-(cons (car L) (cdr L)) -> L
-Append
	-(append 11 12 ..) -> (11 12 ..)
	-(append '(1 2) '(3 4)) -> (1 2 3 4)
	-(append '(1 2) 3) -> (1 2 . 3)
	-(cons '(1 2) '(3 4)) -> ((1 2) 3 4)
-List
	-(list e1 e2 ..) -> (e1 e2 ..)
	-(list 1 2 3) -> (1 2 3)

Four ways to make a list
- '(alpha beta omega)
- (list 'alpha 'beta 'omega)
- (cons 'alpha '(beta omega))
- (append '(alpha beta) '(omega))
-> (ALPHA BETA OMEGA)

-stack operations push and pop as well

-equalities do value type comparisons
-logical predicates And, or , not


--------------------------------------------------------

Artificial Intelligence Lecture 3 Notes

-first test for empty list
-then see if first element is atom then make it base case and do recursive function for rest of list
-then if first element is a list, then apply recursive for first element, and then for the rest of the list

CAR CDR exercises will be on test

Logical Predicates
- (and t t)
	T
- (and t t nil t)
	NIL
- (and 1 2 3 4)
	4
- (or t nil)
	T
- (or 'george nil 'harry)
	george

-or will stop at first true it evaluates
-and will stop at first false it evaluates, or evaluate all the way through

* in assignment we will not be using setq or let

defining functions (defun)
-defun functino-name (arguments) body
- (defun double (n) (*n 2))
- (defun triple (n) (+ n n n))
> (defun bar (x); a function w/multiple statements in
		(setq x(*x3)); its body- it will return the val
		(setq x(/x 2));returned by its final statement
		(+ x 4))

BAR
> (bar 6)
13

-if its recursive then somewhere in the body you invoke the binding

Lambda-binding 
	-if the variable appears in the argument list of a function

-setq assumes whatever follows - set quotation
- set 'x(* x 3) sort of thing

Conditional Logic
-if 
	-(if condition then-result else-result)
	-(if (=7(+ 2 4)) 'yes 'no)-> NO
	-(if 4 5 6) -> 5 (Nil = false, everything else =T)
		-> if 4 then return 5 otherwise return 6
		-> 4 doesn't evaluate to nil so it is "true"
-Cond
	-multiple if-then-else conditional operator
	-(cond (test1 result1)
		   (test2 result2)
		   ...
		   (testN resultN))
	-COND example: colorOf

AND & OR -> Conditionals
-not functions
	-they are not required to evaluate every clause
-can be used to halt evaluation
(defun positivenumberp(x))
	(and (numberp x)(plusp x)))
-Define Logical AND:
(defun logical-and (x y)(and x y t))
	-> Will return only T or Nil

More conditionals: when & unless
-used instead of "if" without then or else clause
-allow any number of statements in body
(WHEN test 
		body)
-if test == nil -> NIL
-Else -> eval BODY and return
		last evaluated form
(UNLESS test
		body)
-if test == T -> NIL
-Else -> eval BODY ...
>(when t 3)
3
>(when nil 3)
NIL
>(unless t 3)
NIL
>(unless nil 3)
3
-(when x a b c) is equivalent to (if x(progn a b c))
-when x is true do the body, otherwise return nil
-unless x is true do the body, otherwise return nil

Arrays
-make-array
	-creates an array; initially all elements are nil
	-array indices start at 0
-Aref
	-accesses the elements of the array created with make-array
>(make-array '(3 3))
#2a((NIL NIL NIL)(NIL NIL NIL)(NIL NIL NIL))
>(aref * 1 1)
NIL
> (make-array 4);1D arrays dont need the extras ()-s
#(NIL NIL NIL NIL)

Two functions
-remember ' means symbol not a function

 	(defun call-up (caller callee)
 		(list 'hello callee 'this 'is
 			caller 'calling))

 	How many arguments does this function require? What are the names of the arguments? What is the result of (CALL-UP 'FRED 'WANDA)?
 	-2 arguments
 	-returns "hello Wanda this is FRED calling"

 	Here is a variation on the CALL-UP function from the previous problem.  What is the result of (CRANK-CALL 'WANDA 'FRED)?

 	(defun crank-call (caller callee)
 		'(hello callee this is caller calling))
 	-this returns
 		(hello callee this is caller calling)

Exercise: Recursive list length
-in-built function: list-length
	(list-length '(A B C))
	3

	(defun recursive-list-length (L)
		"A recursive implementation of list-length."
		(if (null L)
			0
			(+ 1(recursive-list-length (rest L)))))

flat list and want to do summatio recursively

list l = (a b c ...)
 a + sum(b c ....)
 	b + sum(c...)
 		c + sum(d...)

 car(l) = a , and rest = cdr(l)

-t here just means all other cases (like a default for switch statements)
(defun summation n(L)
	(cond ((null L) 0)
		  (t (+ (car L)(summation( cdr L))))
	)
)

> (summation '(1 2 3 4 5))
-quotes is so that it knows the list isn't a function

-what about hierarchical lists though
 S(L) = car(L) + SUM(cdr(L))
 -need to change car(L) to make it work for hierarchical list

 (defun summationHier (L)
	(cond ((null L) 0)
		  ((atom (car L)) (car(L) + summationHier(cdr(L))))
		  (t (+ (summationHier(car L))(summationHier(cdr L))))
	)
)

(cons 2 '(3))
(2 3)

(defun myFlt (L)
	(cond ((null L) nil)
		  ((atom(car L)) (cons (car L)(myFlt(cdr L))))
		  (t (append (myFlt (car L)) (myFlt (cdr L))))))

remember cons is just a list with 1 element

reverse
-minute 1:20 lecture 3

depth
 (defun depth(L)
 	(cond ((null L) 0)
 		  ((atom L) 0)
 		  (t (max (+ 1(depth (car L))(depth(cdr L)))))
 		  ))

(dribble "filepath for it to go to")
(load "file path...")
(dribble)
minute 1:49 lecture 3


the KB, The Einstein Puzzle


Functional Programming with the .NET Framework

Programming Paradigms
-OOP (C#,C++,Java) -> objects
-Procedural (C, Pascal) -> procedurals
-Logic Programming (Prolog) -> Predicates
-Functional (LISP, ML, Haskell, F#) -> functions

-OOP & Procedural -> imperative
	-"How to"
	-GOAL = implicit, ALGORITHM = explicit
-functional and logic -> declarative
	-"What is"
	-GOAL = explicit, ALGORITHM = implicit

About functional programming
-programming paradigm
	-treats computation = evaluation of mathematical functions; avoids state and mutable data
	-contrast to imperative programming style
		-statements that change a program state
	-Lisp,ML,Scheme, Mathematica
-lambda calculus
	-model for functional programming
	-functions that accept other functions as parameters
	-function abstraction and application using variable binding and substitution

Functional Programming in .NET
-C#: LINQ 
	-declarative syntax
	-less errors
	-conciseness of code
-first-class functions : functions as data
	-functions can be passed around b.w. methods
	-functions can be stored in a variable
	-can return functions from a method

C# .NET
-multi-paradigm
-strongly typed
	-imperative
	-declarative
	-functional
	-OO
	-Generic

Functional Support in C#
-anonymous delegates 
	-functions w.o names (in line functions also)
-lambda expressions
-what are delegates?
	-function pointers (event target)
-what is lambda calculus?
	-Expressing computation based on function abstraction and application using variable binding and substitution

Lambda Expressions
-anonymous functions
-used to create delegates or expression trees
-functions as data: input or output
-used in LINQ query expressions
-Lambda operator: =>
-(x,y,...) => f(x,y,...)
-Ex:
	x => x*x or (x) => x*x
	() => btn1.Click()

-interface has no implementation
-abstract class can have virtual methods that can be overrided
	-abstract methods have to be overrided

Delegate example

private delegate vodi HelloWorldDel(string s);
private readonly HelloWorldDel _myDel = n=> Console.WriteLine("Hello {0}", n);

public void HelloWorld()
{
	_myDel("World");
}

Func<int, bool> myFunc = x => x==5;
-last argument type is always return type
bool result = myFunc(4);
	-returns false because 4 != 5

int [] numbers = { 4 , 1, 3, 4 6, 2 ,3 ,5};
int oddNumbers = numbers.Count(n => n%2 == 1);
-counts only those for which this condition holds true

LINQ

Query syntax
var existingPlanTypes = (from s in searchResults.
								   DentalPlanTypes
						where s.Name.Equals(	
								dentalPlanType.Name)
						select s);

if (existingPlanTypes.Count().Equals(0))
{
	searchResults.DentalPlanTypes.Add(dentalPlanType);
}

Order sql server executes queries
FROM
WHERE
GROUP BY
HAVING
SELECT
ORDER BY


Extension Methods Syntax
var enumNames = Enum.GetNames(typeof (PreferenceTypeEnum)).Where(x => x.StartsWith("ReportsToIncludeFor"));
List<State> stateCodes = new List<State>();

if (enumNames != null) //should never be null
	enumNames.ToList().ForEach(x => stateCodes.Add(new State() {Code = x.Substring(x.Length -2)}));

Anonymous Types and Type Inference
var quoteDetail = (from c in ctx.Quote 
					where c.quoteID == quoteId
					select new { c.brokerid })
					.FirstOrDefault();
	-new for anonymous types
	-var shows compile-time type inference

-------------------------------------------------------

Artificial Intelligence Lecture 4 Notes


Intelligent Agents

Overview 
-Rational Agents, Environments
-Good behavior: Rationality
-PEAS
	-Performance, Environment, Actuators, Sensors
-Agent Programs (the structure of agents):
	-simplex reflex agents
	-model-based reflex agents
	-goal-based agents
	-utility-based agents
	-learning agents

Rational Agents
-Successful agents-> agents that can reasonably be called intelligent
-Agents
-Environments
-Coupling b.w. agents and environments
-Rational Agent
	-one that behaves as well as possible
-basic agent designs (skeletons)

Agents and Evironments
-Agent interacts with environments via:
	-sensors-> perception (P*)
	-Actuators-> action (A)
-Agent:
	-humans
	-robots
	-soft-bots
	-thermostats
-Assumption
	-an agent can perceive its own actions (but not always the effects)

Percept & Percept sequence
-Percept:	
	-at time t: the agent's perceptual inputs
-Perceptual sequence:
	-the complete history of everything the agent has ever perceived (entire percept history)
-Agent function: describes agent's behavior:
	f: P* -> A
-Agent Program
	-implementation of f
	-runs on a physical platform/architecture
-Ex:
	-Vacuum-cleaner world

Vacuum-cleaner world
-Percepts
	-location
	-contents
	-e.g. [A, Dirty]
-Actions
	-left
	-right
	-suck
	-NoOp
-Tabulating the agent function:
	-infinite -> impose a limit on percept sequence

Can come in a table format
 
 	Percept, sequence 		|		Action
 	[A, Clean]				|		Right
 	[A, Dirty]				| 		Suck
 	[B, Clean] 				| 		Left
 	[B, Dirty] 				| 		Suck
 	[A, Clean] 				| 		Right

 what is the right function? (agent good/bad)
 Can it be implemented in a small agent program?

Good Behavior
-Agent -> Actions -> Environment -> States
-A rational agent: 
	-one that does the right thing
-the right thing
	-what causes the agents to be more successful
-measures of success = ?
-Fixed performance measure evaluates the environment sequence:
	-one point per square cleaned up in time T
	-One point per clean square per time step, minus one per move
	-Penalize for > k dirty squares

Performance Measures
-General Rule:
	-design performance measures according to what one actually wants in the environment, rather than how one thinks how the agent should behave
-not easy to select a performance measure
-philosophical implications

Rationality; Rational Agent Definition
-What is rational at any given time depends on:
	-performance measure (criterion of success)
	-Agent's a priori knowledge of the environment
	-The actions the agent can perform 
	-Agent's percept sequence to date
-A rational agent chooses whichever action maximizes the expected value of the performance measure given the percept sequence to date

Omniscience, Perfection, Clairvoyance
-Rational != Omniscient
	-omniscience: the agent knows the actual outcome of its actions and can act accordingly (not realistic)
	-percepts may not supply all relevant info
-Rational != Perfect
	-perfection: maximize actual performance
	-Rational: maximize expected performance
-Rational != clairvoyant
	-action outcomes may not be as expected
-> Rational != successful

Rationality - Characteristics
-Information gathering
	-actions targeted to modify future percepts
-Exploration
	-when the environment is unknown (initially)
-Learning
	-From Perceptions
-modifying and augmenting the agent's prior knowledge about the environment
-when the environment is completely known a priori
	-> no need to perceive and learn
-autonomy
	-the agent should learn to compensate for partial or incorrect prior knowledge (of the environment)

PEAS
-PEAS
	-PErformance
	-Environment
	-Actuators
	-Sensors
-to design a rational agent, we must first specify the task environment:
	-the "problem" to which a rational agent is the "solution"
	-different "flavors" -> affects the design for the agent program

Example: Automated Taxi Driver
-Performance Measure??
	-safety, destination, profits, legality, comfort,..
-Environment
	-freeway, pedestrians, weather
-Actuators
	-steering, accelerator, brake, horn, speaker/display
-Sensors
	-video, accelerometers, gauges, engine sensors, keyboard, GPS, microphone/keyboard

-This is describing a Task environment
	-practices at the end of chapter 2

Example: Internet Shopping AGent
-Performance Measure
	-Price, quality, appropriateness, efficiency
-environment
	-current and future WWW sites, vendors, shippers
-actuators
	-display to user, follow URL, fill in form
-sensors 
	-html pages
		-text, graphics, images

Environments
-Real vs. artificial (e.g. keyboard inputs and character output on a screen)
-what matters is the complexity of the relationship among:
	-the agent behavior
	-the percept sequence generated by the environment
	-the performance measure
-software agents (softbots = s/w robots)
	-exist in rich/unlimited domains (e.g. Internet, flight simulator)

Environment Types
-Fully observable vs. partially observable
	-fully observable: if the agents sensors give it access to the complete state of the environment at each point in time
-Deterministic vs. stochastic
	-deterministic: if the next state of the environmet is completely determined by the current state and action executed by the agent
	-partially observable-> may appear stochastic
	-only consider the point of view of the agent
	-Strategic: deterministic except for the action of other agents
-Episodic vs. Sequential
	-episodic: the agent's experience is divided into atomic episodes (perceive + perform a single action); conveyor-belt robot
	-sequential: (chess, taxi driving) short term actions can have long-term consequences
-static vs. dynamic
	-dynamic: if the environment can change while the agent is deliberating
	-semi-dynamic: the agent's performance score is changing, but not the environment (e.g. chess with a clock)
-discrete vs. continuous
	-applied to:
		-state of the environment
		-time handling
		-percepts and actions of agent
-single agent vs. multi-agent
	-which entities msut be viewed as agents?
		-Distinction: Whether B's behavior is best described as maximizing a performance measure whose value depends on agent A's behavior
		--> competitive vs. cooperative

Examples
			solitaire  backgammon internet   taxi
								  shopping   driver
Observable 		yes 	 yes 		no  	 no
Deterministic   yes		 no 		partly   no
Episodic        no  	 no 		no 		 no
Static          yes   	 semi 		semi 	 no
Discrete        yes 	 yes  		yes 	 no 
Single-agent    yes 	 no 		yes      no
								  (except 
								  auctions)
				real world
Observable 		 partially
deterministic 		no
episodic 			no
Static 				no
Discrete  			no
Single-agent 		no

Agent Programs
-Agent function vs. Agent program
	-input for agent function
		-the entire percept history
	-input for agent program
		-the current percept
-table-driven-agent (simplest agent)
	-doomed to failure (huge table sizes)
-key challenge for AI:
	-how to write programs that produce rational behavior from a small amount of code rather than from large number of table entries

Agent Types
-Job of AI: design the agent program
	-implementation of the function mapping percepts to actions
	-Runs on a given architecture
		-a computing device with physical sensors and actuators
-agent = architecture + program
-four basic types in order of increasing generality:
	-simple reflex agents
	-reflex agents with state
	-goal-based agents
	-utility-based agents
-all these can be turned into learning agents

Reflex-Vacuum Agent
function REFLEX-VACUUM-AGENT ([location, status])
	return action
 if status = Dirty then return Suck
 else if location = A then return Right
 else if location = B then return Left
-Action = f(current_percept)
-condition-action rule:
	-if car-in-front-is-braking then initiate-braking
	-same for humans
		-innate reflexes + learned rules

Simple Reflex Agents
function SIMPLE-REFLEX-AGENT (percept) returns action
 state<- INTERPRET-INPUT (percept)
 rule <- RULE-MATCH(state, rules)
 action<- RULE-ACTION [rule]
 return action

 a simple reflex agent works by:
 -finding a rule whose condition matches the current situation (as defined by the percept)
 -doing the action associated with that rule

 Issue with Simple Reflex Agents
 -simple, but very limited intelligence
 -environment must be fully observable!
 	-the agent works only if the correct decision can be made on the basis of only the current percept
 -infinite loops
 	-to avoid: randomize agent actions
 	-randomized behavior of the right kind can be rational in some multi-agent environments
 	-in single-agent environments, randomization is usually not rational

Model-Based Reflex Agents
-If environment is partially observable:
	-keep track of the part of the world it can't see now-> maintain internal state
		-internal state depends on percept history
-model of the world:
	-knowledge about "how the world works"
	-information about how the world evolves independently of the agent
	-information about how the agent's actions affect the world

Model-Based Reflex Agent: Structure
-function REFLEX-AGENT-WITH-STATE(percept)
								returns action
 	static: state, a description of the current world state rules, a set of condition-action rules
	action, the most recent action, initially none
 	state<- UPDATE-STATE (state, action, percept)
 	rule<- RULE-MATCH (state, rules)
 	action<- RULE-ACTION[rule]
 	return action

Goal-Based Agents
-Goal:
	-information that describes situations that are desirable (e.g. taxi driver :: being at the passenger's destination)

More on Goal-Based Agents
-can be easy
	-1 action -> goal satisfied
-or complex:
	-agents may have to consider long sequences of twists and turns to find a way to achieve the goal
	-search
	-planning

Utility-Based Agents
-taxi driver example
	-destination = goal
	-multiple action sequences to achieve goal:
		-some are quicker, safer, more reliable, cheaper..
	-goals-> "happy" vs. "unhappy" states
	-a more general PM: how happy will I be?
	-if a state is preferred to another state -> the state has a higher utility for the agent
-Utility function:
	-maps a state(sequence of states) onto a real number (= the degree of happiness)
		-useful when goals are conflicting or when there is uncertainty in achieving a goal (it weights the likelihood of success against the goal's importance)

Utility based function: structure
-the agent choose the action that leads to the best expected utility:
	- = average over all possible outcome states,
	 weighted by the probability of the outcome

Learning Agents
-learning-> advantages
	-don't need to write so much code (current state of the art: build learning machines and then teach them)
	-allows agents to operate in initially unknown environments and to become more competent than its initial knowledge alone might allow

Learning Agents: Components
-learning element
	-makes improvements
	-uses feedback from critic
-performance element
	-selects external actions
	-(previously the entire agent)
-critic
	-tells the learning element how well the agent is doing w.r.t a fixed performance standard
-problem generator
	-suggests exploratory actions that will lead to ne and informative experiences

F#.NET
-strongly typed
-multi-paradgim
	-functional
	-imperative
	-OO
-Don Syme
-2005: 1.x
-2010: 2.0
-2012: 3.0
-2013: 3.1
-took a litlt from c#, Scala, Erlang, OCaml, Haskell, Python

Main Features
-strongly typed
-unrivaled type inference
-default immutability
-functions as data
-pattern matching
-partial applications
-F# lists
-Pipelining
->highly expressive, concise, predictable code

F# Projects and Writing F# Code
-Creating an F# project in VS.NET
-Order of files w.in a project matters
-top-down evaluation -> no folders allowed
-recursive type definition - must be explicit
-whitespace matters: indentation instead of {}
	-no TABS! -> Configure VS.NET appropriately
-Code organization
	-namespaces
	-modules
-F# file extension: .fs (compiled into .dll/.exe)

Application entry point
[<EntryPoint>]
let main argv = 
	//init code
	0
-implicit return values (no need for "return")
-expressions are everywhere (syllogism below)
	-all expressions return a value
	-functions are expressions 
	-Ergo: all functions return a value

F# demo
-Visual F#
-> F# Application
namespace MyFirstNS
open MyLib
open System

module MyMain =

	[<EntryPoint>]
	int main argv =
		printfn "%n" argv
		let v = 3
		let f1 a (b : int64) = 
			a + b + f1

		f2 2L 3L 4L |> printfn "The result is %d"
		c * (f1 a b)

		Console.ReadLine() |> ignore
		0

//click on project and add new source file
//then add this to project with namespace keyword

module RandLib = 
	open System
	let rand = Random(DateTime.Now.Millisecond)
	let getRandStd () = 
	printfn "Enter the total number of students:"
	let totalStr = Console.ReadLine()
	// returns tuple with true/false, and the total
	let couldParse, total = Int32.TryParse(totalStr)
	if not couldParse
		then "Invalid integer number"
		else let rnum = rand.Next(total) + 1
			sprintf "Student Number picked = %d" rnum

F# interactive
> #help;;

>#load @"C:\dafsdfasdf\Program.fs";;


F# Fundamentals
-Default IMmutability
	-purpose: To avoid unwanted Side Effects = 
		-System state (program data) can change at any time
-Bindings 
	-let, do, use
-Let Bindings:
	-Associate names with values
	-let a = 1
	-let mySum ab = a + b
	-let res = mySum 3 4

F# Types
-Full range of CLI types
-primitives (bool int string float)
-Aggregate types: class, struct, union, record, enum,...
-Built-in Types: tuples, lists, arrays, sequences, records, discriminatd unions
-generic types
-function type: parameter and return type
-objects, interfaces, delegates
-type abbreviations: type aliases
-Collection types: list, array, seq, Map set

F# Type Inference
-C#: var
-Due to top-bottom evaluation, the type inference is much more powerful than in c#
-F# may seem a dynamically typed language, but it is NOT
	-both C# and F# are statically typed 
-type annotations: sometimes needed

List
	let l = [1;2;3]
Array
	let a=[|1;2;3|]
Sequence
	let s = seq{1 .. 3}

[for i in 1..10 -> i] |> printfn "3. List of first 10: %A"
[for i in 1..10 do if i % 2 = 0 yield i] |> printfn "4. Listof first even numbers up to 10: %A"

Sequences
-Nullability
	-NULL is almost never used;
	-null keyword: valid for interoperability's sake
-Option<'T>
	-discriminated union with 2 values
		-some('T)
		-None
	-Essential to F#; syntactic support through the option keyword
		-val middleName : string option = None
		-val middleName : string option = Some "George"

Discriminated Unions
-Values that can be one of a number of named cases, possibly each with different values and types
	-heterogeneous data
	-data with special cases (valid, error)
	-basic inheritance (small object hierarchies)
	-Enums (when only case identifiers are present)

Discriminated Union Example:
type Shape =
	| Rectangle of width : float * length : float
	| Circle of radius : float
	| Prism of width : float * float * height : float

let rect = Rectangle(length = 1.3, width = 10.0)
let circ = Circle(1.0)
let prism = Prism(5., 2.0, height = 3.0)

//the option type is a discriminated union
type Option<'a> = 
	| Some of 'a
	| None

A Binary Tree + Discriminated Union

//very simple tree that stores integer values:
type TreeOfInts = 
	| Nada
	| Node of int * TreeOfInts * TreeOfInts //(value,left, right)

let t = Node (0, Node(2, Nada, Node(5, Nada, Nada)), Node (3, Node (4, Nada, Nada), Nada))

//Tree with nodes as record types

type TreeNode = {name : string; weight : int}
type Tree = 
	| Nil
	| Node of TreeNode * Tree * Tree

//or, using mutually recursive type def
type TreeNodeWithChildren =
	{ name : string; weight : int;
	  left : TreeRec; right : TreeRec }
and TreeRec = 
	| End
	| Node of TreeNodeWithChildren


------------------------------------------------------

Artificial Intelligence Lecture 5 Notes


Solving Problems By Searching

Goal-based agents: Architecture
-Goal:
	-information that describes situations that are desirable (e.g. taxi driver:: being at the passengers destination)
-AI sub-fields
	-search
	-planning

Problem-solving agents
-goal based type of Agents
	-decide what to do by finding a sequence of actionst that lead to desirable states
-problem ?
-solution ?
-general-purpose search algorithms
	-uninformed
		-input = only the problem definition
		-vs. informed search algorithms
-algorithms complexity

PSA continued
-goals
	-simplify the agent's decision problem
	-help organize behavior by limiting the objectives that the agent is trying to achieve
-goal formulation
	-based on:
		-current state/situation
		-agent's performance measure:
			-intelligent agent-> maximize the performance measure
	-goal= set of desired (world) states
-problem formulation (i.e. Agent's tasks)
	-deciding what actions + states to consider given a goal
		-careful at the level of detail

PSA continued
-an agent with several immediate options of unknown value can decide what to do by first examining different possible sequences of actions that lead to states of known value, and ten choosing the best sequence
-Search
	-the process of looking for a sequence of actions
-solution
	-the action sequence (result of algorithm)
-execution (phase)
	-carrying out the recommended actions
-agent design:
	-formulate - search - execute


Ex: Romania

-on holiday in Romania-currently in Arad
-flight leaves tomorrow from Bucharest
-formulate goal:
	-be in Bucharest
-formulate problem
	-states: various cities
	-actions: drive b.w. cities
-find solution:
	-sequence of cities e.g. Arad, Sibiu, Fagaras, Bucharest
-Execution (phase)
	-carrying out the recommended actions

￼
Simple problem solving agent

function SIMPLE-PROBLEM-SOLVING-AGENT( percept) 
								returns an action 
	inputs: percept : a percept
	static: seq : an action sequence, initially empty
		state : some description of the current world 
												state 
		goal : a goal, initially null
		problem : a problem formulation
state ! UPDATE-STATE( state, percept ) 
if seq is empty then
	goal ! FORMULATE-GOAL( state )
	problem ! FORMULATE-PROBLEM( state, goal ) 
	seq ! SEARCH( problem )
action ! FIRST( seq, state ) //recommendation 
seq ! REST( seq, state ) //remainder 
return action

Execution of sequence is blind
	-it ignores its percepts(open-loop system)
		-it assumest aht the solution it has found will always work
-assumptions about the environment
	-static, observable, discrete, deterministic

Well-defined problems...
-a problem -> four components
-intial state (So): in (ARad)
-successor function
	-a description of the possible actions available 
	-S(state) = (action,state)
	-S(In(Arad)) = {(Go(Sibiu),In(Sibiu)),(Go(Timisoara),In(Timisoara)), (Go(Zerind),In(Zerind))}
-Goal test
	-Explicit: {In(Bucharest)}
	-implicit: "checkmate(x)","NoDirt(x)"
-path cost function (additive)
	-E.g. Sum of distances, number of actions executed, etc.
	-c(x,a,y) is the step cost, assumed non-negative

...And Solutions
-solution
	-a path from the initial state to a goal state
-solution quality
	-measured by the path cost function
-optimal solution
	-has the lowest path cost among all solutions
-problem-solving algorithm
	-input
		-the four components of the problem (complex data structure)
	-output
		-the solution

Formulating Problems
-state space
	-initial state + successor function
-path in the state space
	-sequence of states connected by a sequence of actions
-real world:
	-ridiculously complex -> state space >>>
	-abstraction of state space for problem solving
		-removing detail from the state space representation
		-is valid if we can expand any abstract solution into a solution in the detailed world
		-is useful if it simplifies the execution phase
-toy problems vs. real world problems

States??  
	(8 states) dirt and robot locations (ignore dirt amounts, ..)

•Actions??
	Left, Right, Suck, (NoOp)

•Successor
function??
	Generates the legal states shown in diagram 

•Goal test??
	No dirt (all squares)

•Path Cost??
	1 per action (0 for NoOp) = # steps in path

Number of states for N locations
N cells, dirt or no dirt
2^N

Example the 8-puzzle
● States:
	● integer locations of tiles (abstraction??)
● Actions:
	● move blank left, right, up, down
● Goal test:
	● = goal state given above
● Path cost:
	● 1 per move (= # steps in the path)
	● [Note: optimal solution of n-Puzzle family is NP-hard]
-board for N tiles is NP-hard

Example: Robotic Assembly
● states??
	● real-valued coordinates of robot joint angles 
	● parts of the object to be assembled
● actions??
	● continuous motions of robot joints 
● goal test??
	● complete assembly with no robot included!
● path cost??
● time to execute

Real World Problems
● Route-finding problem
● Touring problem
● Traveling Salesperson Problem (TSP) 
● VLSI Layout
● Robot navigation
● Automatic assembly sequencing
● Protein design
● Internet searching (Chapter 10)

Classification of Search Problems
● Do we have a complete description of the search space?
	● NO:
		●Online Search Problem
	● YES:
		● No additional information
			●Uninformed Search Problem
		● Rough information on the topology of the search space
			●Heuristic Search Problem
		● Structured information on the property of being a goal:
			●Constraint Satisfaction Problem

Classification of Search Algorithms
● Path stored?
	● NO:
		●Local Search
	● YES:
		● Memory space becomes a resource problem
		● Are cycles detected? 
			●NO: Tree Search 
			●YES: Graph Search

Search for Solutions
● Search tree (or graph)
	● Generated by the initial state and the successor function (state space)
● Search node
	● The node currently expanded in the tree
● Expanding the current state:
	● Applying the successor function to the state 
	● Generates new set of states
● Search strategy:
	● The choice of which state to expand next
● State space (or state) vs. search tree (or node)
Slide 20
	● Holiday in Romania: 20 cities->20 states
	● Infinite number of search paths in the state space

From Arad we can go to 3 cities - apply actions and build new states from original state
-take left most node and degree is 4 so you can go to 4 places from there
	-forget about where you're coming from (so include parent node as one of its children always)

More Definitions
Fringe
	● The collection of nodes that have been generated but not yet expanded
￼	● Implemented as a queue
● Queue operations:
	● MAKE-QUEUE(element, ...) 
	● EMPTY?(queue)
	● FIRST(queue)
	● REMOVE-FIRST(queue)
	● INSERT(element, queue)
	● INSERT-ALL(elements, queue)

Search Strategy
● A search strategy
	● Is defined by picking the order of node expansion
● Strategies are evaluated along the following dimensions:
	● completeness: does it always find a solution if one exists? 
	● optimality: does it always find a least-cost solution?
	● time complexity: number of nodes generated
	● space complexity: maximum number of nodes in memory
● Time and space complexity (AI) are measured in terms of
	● b: branching factor of the search tree (maximum number of successors of any node)
	● d: depth of the least-cost solution (shallowest goal node)
	● m: maximum depth of any path in the state space (may be ∞)

Uniformed (Blind) Search Strategies
● Uninformed strategies:
	● Use only the information available in the problem definition
		● Generate successors
		● Distinguish between goal and non-goal states
● Uninformed search strategies
	● Breadth-first search (BFS) 
	● Uniform-cost search
	● Depth-first search (DFS) 
	● Depth-limited search
	● Iterative deepening search
● Search strategies differ by the order in which
￼nodes are expanded

Breadth-first search
-expand shallowest unexpanded node
-implementation 
	Fringe = FIFO queue
		-new successors go at the end
- allows expand nodes on 1 level before moving on to next level

Properties of BFS
● Complete?
	● Yes (if b is finite)
● Time?
	● 1+b+b2+b3+... +bd + b(bd-1) = O(bd+1)
● Space?
	● O(bd+1) (keeps every node in memory)
● Optimal?
	● Yes (if cost = 1 per step); 
	● Not optimal in general
● Space is the bigger problem (more than time)
	● Can easily generate nodes at 100MB/sec

Uniformed-Cost search
● Expand least-cost unexpanded node (i.e. with the lowest path cost)
● Implementation:
	● fringe = queue ordered by path cost
● Equivalent to breadth-first if step costs all equal
● Complete?
	● Yes, if step cost ≥ ε
● Time?
	● # of nodes with g ≤ cost of optimal solution, 
	● where C* is the cost of the optimal solution
● Space?
	● # of nodes with g ≤ cost of optimal solution
● Optimal?
	● Yes – nodes expanded in increasing order of g(n)

**THESE ARE ALL ON EXAM

Depth-first search (DFS)
● Expand the deepest unexpanded node 
● Implementation:
	● Fringe = LIFO queue (stack) 
		● Put successors at front of list

Properties of DFS
● Complete?
	● No: fails in infinite-depth spaces, spaces with loops
	● Modify to avoid repeated states along path 
	->complete in finite spaces
● Time?
	● O(bm): terrible if m >> d
	● But if solutions are dense, may be much faster than breadth-first search
● Space?
	● O(bm), i.e., linear space!
● Optimal? 
	● No


Depth-Limited search
● = DFS with limit (l) on depth to search 
	● i.e. Nodes at depth l have no successors
● Alleviates the problem of unbounded trees
● Disadvantage:
	● Incompleteness if l < d
		● (d = the depth of the shallowest solution node)
	● Non-optimal when l > d
● Time: O(bl)
● Space: O(bl)
● -> DFS = DLS(l=∞)

Depth Limited Search cont.
● How to select the limit?
	● E.g.: Holiday in Romania
		20 cities -> if solution exists, then length <= 19
	● l = 19 Diameter =9
	● l= 9 
● Note:
	● For most problems, we will not know a good depth limit until we have solved the problem
● DLS can terminate with 2 kinds of failure:
	● Standard failure value (i.e. no solution)
	● Cutoff value (i.e. no solution within the depth limit)

Iterative Deepening Search
● A.k.a. Iterative deepening DFS
● Finds the best depth limit
● Gradually increases the limit: 0, 1, 2, ... until a goal is found, i.e. when l = d
	● (d = the depth of the shallowest goal node)
● Combines the benefits of BFS and DFS:
	● (DFS):
		● Space = linear: O(bd)
	● (BFS):
		● Complete, when b=finite
		● Optimal, when the path cost = a non-decreasing function of the depth of the node

IDS algorithm
-very important that you know how this works

function Iterative-Deepening-Search
-psuedo code on slide 40

Properties of IDS
● Complete?? ●Yes
● Time??
	●(d + 1)b0 + db1 + (d -1)b2 + ... + bd = O(bd)
● Space?? 
	● O(bd)
● Optimal??
	●Yes, if step cost = 1
	●Can be modified to explore uniform-cost tree

-IDS does better b.c. other nodes at depth d are not expanded 
-BFS can be modified to apply goal test when a node is generated

Bidirectional Search
● Two simultaneous searches from start an goal.
	● Motivation: b^(d/2) + b^(d/2) < b^d
		-forward search, backward search
● Check whether the node belongs to the other fringe before expansion.
● Space complexity is the most significant weakness.
● Complete and optimal if both searches are Breadth-First.
● The predecessor of each node must be efficiently computable.
	● Works well when actions are easily reversible.


Graph Search
● Tradeoff between space and time:
	● Algorithms that forget their history are doomed to repeat it
	● If an algorithm remembers every state it has visited -> algorithm = viewed as exploring the state-space graph
		● Closed list: states visited
		● Open list: the fringe of unexpanded nodes

Searching with Partial Information:
Problem Types
● Single-state problem
	● E:= Deterministic, fully observable
	● Agent knows exactly which state it will be in 
	● Solution is a sequence
● Conformant problem
	● E: = Non-observable or partially observable 
	● Agent may have no idea where it is
		● Agent must reason about sets of states = belief state 
	● Solution (if any) is a sequence
● Contingency problem
	● E:= Nondeterministic and/or partially observable
	● Actions are uncertain (Problem may be “adversarial”)
	● Percepts provide new information about current state
	● Solution is a contingent plan or a policy

Summary
● Search process:
	● Sequence of actions to achieve goals 
	● Applied for environments which are:
		● Deterministic, observable, static, completely known
● First formulate the goal then the problem
● Problem components:
	● Initial state, set of actions, a goal test function, a path cost function
	● Environment = state space
● Solution
	● = a path through the state space from initial state to goal state
● Search algorithms comparison aspects:
	● Completeness, optimality, complexity (time + space) Slide 52
￼￼￼￼￼￼￼￼
Summary
● Breadth-first search
	● Selects the shallowest unexpanded node
	● Complete, optimal (step cost=1), time/space complexity
￼￼￼￼￼￼￼￼= O(bd+1)
	● Uniform-cost search
		● Expands the node with lowest path cost, g(n)
● Depth-first search
	● Expands the deepest unexpanded node 
	● Not complete, non-optimal
	● Time: O(bm), Space: O(bm)
● Depth-limited search: Fixed depth limit on DFS
● Iterative deepening search
	● d x DLS until a solution is found
	● Time: O(bd); Space: O(bd)


Informed Search and Exploration

Informed (Heuristic) SEarch Strategies
-Informed search strategy
	-one that uses problem-specific knowledge beyond the problem definition
	-finds solutions more efficiently than uninformed (i.e. blind) search
-Heuristic
	-a method to help solve a problem (informal)
	-often rapidly leads to a solution that is usually reasonably close to the best possible answer
		-"rule of thumb"
		-educated guess
		-intuitive judgement
		-common sense

Best-First Search
-greedy approach
-an instnace of TREE/GRAPH-SEARCH algoritm where we expand the most desirable node
-expand node n based on an evaluation function, f(n)
-f(n) measures distance to the goal
	-select the node with lowest f(n)
-fringe implementation
	-priority queue
		-data structure taht will maintain the fringe in ascending order of f-values
-expand what "appears" to be best (according to f), not really the best node
	-unless f is indeed accurate, then it truly is "best"


Best-first search algorithm
-different evaluation functions
-heuristic function: h(n)
	-estimated cost of the cheapest path from node n to a goal node
-E.g. routing problem in Romania
	-h = the straight-line distance (SLD) Arad-Bucharest
-assumption
	-if n=goal node, then h(n) = 0
-two best-first search algorithms
	-Greedy best-first search
	-A* search

Greedy Best-First Search
-AKA "greedy search" or "best-first search"
-method:
	-expand the node that appears to be closest to the goal
		-i.e. it is likely to lead to a solution quickly
	-evaluate nodes using just the heuristic function:
		f(n) = h(n)
-example: holiday in Romania
	-heuristic (h): straight line distance
		-h_sld(n) = straight line distance from n to Bucharest
-basically just choose cheapest everytime in relation to goal

Issues with Greedy Search
-false starts
	-b.c. of minimizing h(n)
		-e.g. consider lasi -> Fagarasi
			-takes you to a dead end or infinite loop
-repeated states
	-if they are not avoided -> the solution will never be found (infinite loop)
-resembles DFS (follow one path to goal)
-same defects as DFS:
	-not optimal, incomplete
		-complete if unique states and finite search space
	-time/space complexity: O(b^m)
		-m = maximum depth of the search space


A* Search
-don't look just ahead, but also look at where we have been (path cost to this state)
-goal
	-minimize the total estimated solution cost
-evaluation function:
	f(n) = g(n) + h(n)
		g(n) = cost to reach n
		h(n) = the estimated cost from n to the goal node
	f(n) = estimated cost of the cheapest solution through n
-minimize g(n) + h(n)
-A* = optimal and complete
	-note some conditions apply on h(n)

Admissable Heuristic
-never over estimates
-a heuristic h(n) is admissible if:
	h(n) never overestimates the cost to reach the goal, i.e. it is optimistic
-a heuristic h(n) is admissible if for every node n, 
	h(n) <= h*(n), where h*(n) is the true cost to reach the goal state from n
-also require h(n) >= 0, so h(G) = 0 for any goal G
	h_SLD(n) never overestimates the actual road distance

A* search on midterm ********

Optimality of A*
-theorem 
	-A* using TREE SEARCH is optimal if h(n) is admissible

Consistent heuristics
-a heuristic is consisten if for every node n, ever successor n' of n generated by an action a
	h(n) <= c(n,a,n') + h(n')

-if h is consistent ->
	f(n') = g(n') + h(n')
		  = g(n) + c(n,a,n') + h(n')
		  >=g(n) + h(n)
		  = f(n)
-i.e. f(n) is non-decreasing along any path

Analysis of A*
-complete?
	-yes
		-unless infinitely many nodes with f<=f(G)
-time complexity
	-exponential
-space complexity
	-keeps all nodes in memory?
-optimal
	-yes
-if C* = the cost of the optimal solution path, then:
	A* expands all nodes with f(n) < C*
	A* expands some nodes with f(n) = C*
	A* expands no nodes with f(n) > C*a

More about A*
-uniform cost search (uninformed search)
	=A* with h(n) = 0
		-bands are circular around the initial state
-pruning
	-eliminating possibilities from consideration w.o having to examine them
		e.g. subtree of Timisoara
-A*
	-optimally efficient
		-no other optimal algorithm is guaranteed to expand fewer nodes than A*, except when breaking a tie when f(n) =C*
	-usually runs out of space long before it runs out of time


Memory Bounded Heuristic Searches

Improving space complexity
IDA* -iterative Deepening A*
	-apply the idea behind iterative deepening 
	->IDA* algorithm
	-cutoff = f-cost instead of depth
-RBFS = Recursive best first search
	-similar to recursive DFS, but keeps track of the f-value of the best alternative path available from any ancestor of the current node
	-space complexity = linear
-MA* & SMA* (memory-bounded & simplified)
	-use all available meory: expand the best leaf until memory is full
	-regenerate a subtree only when all other paths have been proven to look worse than a forgotten path

Heuristic Functions

Admissible Heuristics
-E.g. for the 8 puzzle
	h_1(n) = number of misplace puzzles
	h_2(n) = total Manhattan distance (aka city block distance)
	how do you determine which one is better?
h_1(S) = 8
h_2(S) = 3 + 1 + 2 + 2 +2 +3 +3 +2 = 18

the one closest to the actual cost (without overestimating should be used)
-the average cost is 22 steps
-the true cost (here) 26 steps

Dominance
-which every heuristic function is greater than the other for all possible states, then it dominates other

Relaxed Problems
-a problem with fewer restrictions on the actions is called a relaxed problem 
-the cost of an optimal solution to a relaxed problem is an admissible heuristic for the original problem

Pattern Matching
 
 let exists (x : int option) = 
 	match x with
 	| Some(x) -> true
 	| None -> false

 let print tuple1 = 
 	match tuple1 with
 	  | (a,b) -> printfn "Pair %A %A" a b

 let getShapeHeight shape = 
 	match shape with
 	| Rectangle(height = h) -> h
 	| Circle(radius = r) ->2. * r
 	| Prism(height = h) -> h


-need . b/c r is float and 2 is not
-need to match all shape options

recursion F# on slide 29

Functions - Basics
-in f# if you don't pass a function all of its required arguments then it returns you a function of the remaining arguments (with the ones you did give it plugged in)

-scope & shadowing (when reusing names)
-parameters: explicit or inferred
	let f x = x+1
-Bodies & Return values
	-let cylinderVolume radius length : float = 
		//define a local value pi
		let pi = 3.1415926
		length = pi* radius * radius
-calling it 
	let val = cylinderVolume 2.0 3.0
-Partial application of arguments
-currying = creating new functions by partial application of argument
	F(x,y,z)
	F(2) = G(y,z)
	F(2,3) = H(z) = G(3,z)
	F(2,3,4) = G(3,4) = H(4)

functions defined in functions

functions as arguments to other functions

	let apply1 (transform : int ->  int) y = transform y

-lambda expressions (unnamed functions) 

	let result 3 = apply1( fun x -> x+1) 100
	let result 4 = apply2( fun x y -> x*y) 10 20

-recursive functions
	let rec fib n = if n <2 then 1 else fib (n -1) + fib(n-2)

function composition and pipelining
-pass output from one function to the other function

-composition >> and <<
let function1 x = x + 1
let function2 x = x + 2
let h = function1 >> function2
let results = h 100

-pipelining |> and <|
	-let result = 100 |> function1 |> function2





-------------------------------------------------------

Artificial Inteligence Lecture 6 Notes


Local Search Algorithms
-in many optimization problems, the path to the goal is irrelevant; the goal state itself is the solution
-search space = set of 'complete' configurations 
	-space of candidate solutions
-consider finding solutions that represent configurations satisfying a set of constraints:
	-n-Queens problem
		-the order in which the queens are added is irrelevant
		-the path in the search tree/graph = irrelevant
-in such cases we can use local search algorithms: keep a single current state, try to improve it
	-dont care about multiple paths
		-paths followed by the search are not retained
	-not a systematic approach


Local search and optimization
● Initial State = candidate solution
● Successor function = one that iteratively generates states towards a neighbor candidate solution
	● Neighborhood relationship between candidate solutions 
	● Apply changes iteratively to one or more components of the current state
● Metaheuristic (general heuristic method)
	● Algorithmic framework designed to find, generate, and select a lower-level procedure or heuristic to solve an optimization problem

Metaheuristic
● Useful approaches for (combinatorial) optimization problems (e.g. TSP)
	● Not problem-specific 
● Goal:
	● Iteratively improve a candidate solution with regard to a given performance measure
● Drawback:
	● Solution is not guaranteed to be optimal
	● Algorithms are approximate and non-deterministic

Advantages of Local Search


Advantages of Local Search
A 	Low memory requirements: O(1)
B 	Finding reasonable solutions in large/infinite (
	continuous) state spaces
● Pure optimization problems:
	● Find the best state given an objective function
● Nature’s objective function = reproductive fitness 
	● No “goal test”
	● No “path cost”

Ex: n-queens
-put n queens on an nxn board with no 2 queens on the same row, column, or diagonal:
	-no queen attacking any other queen
	-counting solutions

State space landscape
-location (state) & elevation (h or f)
	-elevation [] cost -> find globabal minimum
	-elevation [] objective function -> find global maximum
-Complete vs. optimal local search algorithm


Hill-climbin search
● "Like climbing Everest in thick fog with amnesia“!go uphill only
● Record only current state and objective function value
￼￼￼● No search tree to maintain/save
	● Look up only immediate neighbors, nothing beyond that

Hill-climbing search: 8-queens problem
-Use a complete-state formulation:
	-each state-> 8 quens on the board, one per column
-successor function:
	-returns all possible states generated by moving a single queen within its column
	-one state -> 8x7 successors
-heuristic function: 
	-h = # of pairs of queens attacking each other, directly or indirectly

Hill-Climbing Search
● Greedy local search
	● It selects a good neighbor state w/o thinking ahead; 
	● It there is a tie, it chooses randomly
● Often, greedy does pretty good
	● Rapid progress towards a solution
	● Always trying to improve a bad state
● Problems:
	● Local maxima: local peak < global maximum 
	● Ridges: a sequence of local maxima
	● Plateaux & Shoulders : flat evaluation function


Hill-climbing search
-main issue:
	-depending on initial state, can get stuck on local maxima

Hill-climbing search
-ridges 
	-a sequence of local maxima
	-for each local maxima all available actions point downhill

Hill-climbing search: statistics
● 8-queens problem using steepest ascent (greedy) hill climbing
	● Stuck: 86% vs. Success:14% 
	● Works very quickly:
		● 4 steps (success) vs. 3 steps (stuck) 
		● State space = 88 
● Allowing a limited # of sideways moves (plateau / shoulder)
	● Improves success rate (14%!94% !!!)
	● The cost: 4!21 steps (success); 3!64 (failure)
● Many variations of hill climbing
	● Stochastic hill-climbing (choose randomly the next uphill
￼￼￼￼● First-choice hill climbing (when a state has many successors,
￼￼￼￼￼￼￼￼
￼
all hill-climbing algorithsm = incomplete
-random-restart hill-climbing = complete
	-series of hill-climbing searches from randomly generated initial states until a goal is found

Simulated Annealing search
● If always “uphill”->incomplete, but efficient 
● If always (uniformly) random->complete, but
inefficient
● -> Combine hill climbing with random walk
	● Goal: completeness & efficiency
	● Annealing (Metallurgy):
		● = Process used to temper or harden metals and glass by heating them to a high temperature and then gradually cooling them


Simulated Annealing Search
●Gradient Descent = Minimizing Cost
●Allow random moves (instead of the best)
	● If state is improved!always accept this move
	● Else!accept move with probability < 1
		● The probability decreases exponentially with the “badness” of the move
		● Bad moves are more likely to be accepted in the beginning (‘when the temperature T is high’)
		● Bad moves become more unlikely as T goes down
		● If the cooling rate lowers T slowly enough, the algorithm will find a global optimum with probability approaching 1
● Applied to VLSI layout problems (‘80s), job scheduling, and other optimization problems

Simulated Annealing Search
-idea: escape local maxima by allowing some "bad" moves but graduall decrease their frequency

Local Beam Search
● Keep track of k states rather than just one
● Start with k randomly generated states
● At each iteration, all the successors of all k states are generated
	● If any one is a goal state, stop;
	● Else select the k best successors from the complete list and repeat.
	● Local beam search [] random-restart search
		-in random-restart search each search process runs independtly of the others
		-in local beam search, useful information is passe among the k parallel search threads

Local Beam Search
-problem
	-possible lack of diversity among the k states
-stochastic beam search
	-instead of k best select k successors at random with the probability of choosing a given successor = increasing function of its value
	-similar to the process of natural selection
		● The successors (offspring) of a state (organism) populate the next generation according to its value (fitness)


Genetic Algorithms
● A successor state is generated by combining two parent states
● Start with k randomly generated states (population)
● A state is represented as a string over a finite alphabet
(often a string of 0s and 1s)
● Evaluation function (fitness function):
	● Higher values for better states
● Produce the next generation of states by:
￼￼￼￼● Selection
	● Crossover
	● Mutation

Genetic algorithms: 8-queens problem

● Fitness function: number of non-attacking pairs of queens min = 0, max = 28 <- WHY?
● Computing the fitness function:
● 24/(24+23+20+11) = 31%
● 23/(24+23+20+11) = 29%
● etc.

-the cut point to do crossover doesn't have to be same for 2 pairs, but it will be given to you where to cut

-take 1 column and change the value at random for the mutation

-want to choose a column that has a duplicate row to mutate

-first and foremost you need to know how to calculate the number of non-attacking pairs ****** on test


Genetic Algorithms
-Crossover Point = after 3rd digit in the position string [3,2,7,5,2,4,1,1]
● Crossover
	● Large steps in the state space early in the search process, when population is diverse
	● Smaller steps later on, when the individuals are similar



Offline Search vs. Online Search
● Offline search agents
	● Compute a solution before setting foot in the real world;
then execute solution & disregard percepts
● Online search agents
	● Interleave computation and action
		● E.g. takes an action and then observes environments and then computes the next action
￼￼￼￼● In (semi-)dynamic or stochastic environments 
	● Necessary for an exploration problem
		● States and actions are unknown
			● Actions = experiments to determine the next action
		● E.g. map-building robot in a new building, or labyrinth

Online Search Problems
● Agents are assumed to know only the following:
	● ACTIONS(s): returns a list of actions allowed in state s 
	● c(s,a,s’): this step-cost cannot be used until the agent knows that s’ is the outcome 
	● GOAL-TEST(s)
●The agent cannot access the successors of a state except by actually trying all the actions in that state
● Assumptions
	● The agent can recognize a state that it has visited before
	● Actions are deterministic
	● Optionally, an admissible heuristic function h(s)


Online Search Problems
● If some actions are irreversible, the agent may reach a dead end
● No algorithm can avoid dead ends in all state spaces (adversary argument)
● Assumption: the state space is safely explorable, i.e. some goal state is reachable from every reachable state

Online Search Agents
● Online algorithm can expand only a node that it physically occupies
	● Offline algorithms can expand any node in the fringe 
	● Offline node expansion = simulated action
	● Online node expansion = real action
● Same principle as DFS
	● Expand nodes in a local order
	● Additionally, the agent will store its map in a table

Online DFS
function ONLINE_DFS-AGENT(s’) return an action
	input: s’, a percept identifying current state
	static: result, a table of the next state, indexed by action and state, initially empty
		unexplored, a stack that lists, for each visited state, the action not yet tried unbacktracked, a stack that lists, for each visited state, the predecessor states agent has not yet backtracked
		s, a, the previous state and action, initially null 
	if GOAL-TEST(s’) then return stop
	if s’ is a new state then unexplored[s’][]ACTIONS(s’) 
	if s is not null then do
		result[a,s][]s’
		add s to the front of unbackedtracked[s’]
	if unexplored[s’] is empty then
		if unbacktracked[s’] is empty then return stop
		else a[] an action b such that result[b, s’]=POP(unbacktracked[s’])
	else a [] POP(unexplored[s’]) 
	s [] s'
	return a

Online DFS, exampel

● Assume maze problem on 3x3 grid.
● s’ = (1,1) is initial state
● Result = empty
● UX (unexplored)= empty
● UB (unbacktracked) = empty
● s, a are also empty



Online DFS, example

● GOAL-TEST((1,1))?
	● s’ != G, thus false
● (1,1) a new state?
	● True
	● ACTIONS((1,1)) → UX[(1,1)]
		● {RIGHT,UP} 
● s is null?
	● True (initially)
● UX[(1,1)] empty?
	● False
● POP(UX[(1,1)]) → a


Online Local Search
● Hill-climbing is already online
	● One state is stored.
● Bad performance due to local maxima
	● Random restarts impossible.
● Cannot implement random restart (Why?)
● Solution1: Random walk introduces exploration
	● Selects one of the available actions at random 
	● Preference to not-yet-tried action
	● Can produce exponentially many steps

Online Local Search
● Solution 2: Add memory to hill climbing search
	● Store current best estimate H(s) of cost to reach goal 
	● H(s) is initially the heuristic estimate h(s)
	● Afterward updated with experience
● Learning real-time A* (LRTA*)


Learning Real-Time A*(LRTA*)
slide 45

Constraint Satisfaction Problem (CSPs)
● Standard search problem:
	● state is a "black box“ – any data structure that supports successor function, (problem-specific) heuristic function, and goal test
● CSP:
	● state is defined by variables Xi with values from domain Di
	● goal test is a set of constraints Ci specifying allowable combinations of values for subsets of variables
● Allows useful general-purpose algorithms with more power than standard search algorithms

Example: Map -Coloring
Variables WA, NT, Q, NSW, V, SA, T
Domains Di = {red, green, blue}
Constraints: adjacent regions must have different colors
For example: WA ≠ NT, or
(WA, NT) []{(red, green), (red, blue), (green, red), (
			green, blue), (blue, red), (blue, green)}

Constraint Graph
● Binary CSP:
	● each constraint relates two variables
● Constraint graph: 
	● nodes are variables
	● arcs are constraints
● General-purpose CSP algorithms use the graph structure to speed up search.
	● E.g., Tasmania is an independent sub-problem!

Standard Search Formulation
● States are defined by the values assigned so far
	● Initial state: the empty assignment { }
	● Successor function: assign a value to an unassigned
variable that does not conflict with current assignment
		● ->fail if no legal assignments
	● Goal test: the current assignment is complete 
	● Path cost: constant (e.g. 1) for every step
● This is the same for all CSPs! (A GOOD thing)
● Every solution appears at depth ??
	= n , with n variables->use depth-first search (DFS)
● how many possible complete assignments of n variables on a domain of size d?
● path is irrelevant -> can also use complete-state formulation

-DFS better than BFS because uses less space

Varieties of CSPs
● Discrete variables
	● finite domains:
		● n variables, domain size d -> O(d n) complete
assignments
		● e.g., Boolean CSPs, incl. ~Boolean satisfiability (3SAT) (NP-complete)
	● infinite domains:
		● integers, strings, etc.
		● e.g., job scheduling, variables are start/end days for each job
		● need a constraint language, e.g., StartJob1 + 5 ≤ StartJob3
￼● Constraints: linear or nonlinear
	-e.g. start/end times for Hubble Space telescope
	-linear constraints solvable in polynomial time by linear programming (LP) methods

Variety of Constraints
● Unary constraints involve a single variable,
	● e.g., SA ≠ green
● Binary constraints involve pairs of variables,
	● e.g., SA ≠ WA
● Higher-order constraints involve 3 or more
variables,
	● e.g., cryptarithmetic column constraints
● Preferences (soft constraints vs. absolute constraints)
	● E.g. red is better than green
	● Representable by a cost for each variable assignment
		● -> Constraint optimization problems
		● -> Use optimization search methods (path-based or local)

Example: Cryptarithmetic
	● A.k.a. “Verbal arithmetic”
● = a type of a mathematical game:
	● Mathematical equation!unknown numbers whose digits are represented by letters.
		● Similar to puzzles with non-alphabetic symbols 
		● Operations: addition, multiplication, division
		● Classic example (1924, Henry Dudeney):
			● Solution to the puzzle:
			● O = 0, M = 1, Y = 2, E = 5
			● N = 6, D = 7, R = 8, S = 9


Cryptarithmetic
● RULES:
	● Each letter or symbol represents only one digit throughout the problem;
	● When letters are replaced by their digits, the resultant arithmetical operation must be correct;
	● The numerical base, unless specifically stated, is 10; 
	● Numbers must not begin with a zero;
	● There must be only one solution to the problem.


Another Cryptarithmetic Example
● Variables: F T U W R O X1 X2 X3
● Domains: {0,1,2,3,4,5,6,7,8,9}
● Constraints: Alldiff (F,T,U,W,R,O)
	● O + O = R + 10 · X1
	● X1 + W + W = U + 10 · X2
	● X2 + T + T = O + 10 · X3


Real-World CSPs
● Assignment problems
	● e.g., who teaches what class
● Timetabling problems
	● e.g., which class is offered when and where?
● Transportation scheduling
● Factory scheduling
● Floor planning

Backtracking search
● b = (n - l +1)[]d at depth l, hence n! · dn leaves!!! 
	-> Very BAD!!
● Variable assignments are commutative, i.e.,
	● [WA = red then NT = green] same as [NT = green then WA = red]
● Only need to consider assignments to a single variable at each node
	● -> b = d and there are dn leaves
● Depth-first search for CSPs with single-variable assignments is called backtracking search
	● Chooses values for one variable at a time
	● Backtracks when a variable has no legal values left to assign
	● Backtracking search is the basic uninformed algorithm for CSPs 
	● Can solve n-queens for n ≈ 25
pseudo code on line 21

Most constrained variable 
	-choose the variable with the fewest legal values
-aka minimum remaining values (MRV)
-aka fail-first heuristic

-tie breaker among most constrained variables
-most constrained variable
	-choose the variable with most constraints on remaining variables = degree heuristic
		-attempts to reduce the branching factor on future choices

least constraining variable
-given a variable, choose the least constraining value:
	-the one that rules out the fewest remaining variables
		-combining these heuristics makes 1000 queens feasible

Forward checking
-idea:
	-keep track of remaining legal values for unassigned variables
	-terminate search when any variable has no legal values

Arc consistency
-simplest form of propagation makes each arc consistent
- X -> Y is consistent iff
	-for every value x of X there is some allowed value y of Y

Example: 4-Queens
● States: 4 queens in 4 columns (44 = 256 states)
● Actions: move queen in column
● Goal test: no attacks
● Evaluation: h(n) = number of attacks
● Given random initial state, can solve n-queens in almost constant time for arbitrary n with high probability (e.g. n = 1,000,000 -> 50 steps)


Example: 8-Queens
● A two-step solution for an 8-queens problem using min-conflicts.
● At each stage, a queen is chosen for reassignment in its column.
● The number of conflicts (in this case, the number of attacking queens) is shown in each

Local Search for CSP: Applications
● Min-Conflicts: works well for hard problems 
● E.g.: Scheduling observations for the HST
	● Initially: 3 weeks needed to schedule a week of observations
	● With Min-Conflicts: 10 minutes!!
● Local search can be used in an online setting when the problem changes
	● Scheduling problems: airline schedule
		● Thousands of flights
		● Tens of thousands of personnel assignment
		● Bad weather at one airport->schedule = infeasible
			●->Use local search and start from current schedule
			● Backtracking with a new set of constraints may not be good

Completely independent problems are rare

Tree structured CSP
● Theorem:
		If the constraint graph has no loops, the CSP can be solved in O(nd2) time
	● Compare to general CSP: worst-case = O(dn)


Nearly Tree-Structured CSPs
● Conditioning:
	● Instantiate a variable, prune its neighbors’ domains 
● Cutset conditioning:
	● Instantiate (in all ways) a set of variables such that the remaining constraint graph is a tree

● Tree decomposition:
	● Three requirements that must be satisfied
	● Solve each problem independently
	● In any one has no solution!the entire problem has no solution
	● Build general solution

		● CSP with constraint graphs of bounded tree width (w) are solvable in polynomial time: O(ndw+1)
		● Finding the tree decomposition with minimal tree width is NP-hard

Summary
● CSPs are a special kind of problem:
	● states defined by values of a fixed set of variables 
	● goal test defined by constraints on variable values
● Backtracking = depth-first search with one variable assigned per node
● Variable ordering and value selection heuristics help significantly
● Forward checking prevents assignments that guarantee later failure

Glossary of Terms
● A constraint satisfaction problem is a problem in which the goal is to choose a value for each of a set of variables, in such a way that the values all obey a set of constraints.

● A constraint is a restriction on the possible values of two or more variables. For example, a constraint might say that A=a is not allowed in conjunction with B=b.

● Backtracking search is a form of DFS in which there is a single representation of the state that gets updated for each successor, and then must be restored when a dead end is reached.

● A directed arc from variable A to variable B in a CSP is arc consistent if, for every value in the current domain of A, there is some consistent value of B.

● Backjumping is a way of making backtracking search more efficient by jumping back more than one level when a dead end is reached.

● Min-conflicts is a heuristic for use with local search on CSP problems. The heuristic says that, when given a variable to modify, choose the value that conflicts with the fewest number of other variables.

-------------------------------------------------------

Artificial Intelligence Lecture 8 Notes

Adversarial Search

Games-on final
● Multi-agent environments
	● Unpredictability of the opponent(s)
	● Contingencies are introduced into the agent’s problem-solving process
	● Cooperative vs. Competitive
● Adversarial search problems = Games
● Mathematics: game theory 
	● The impact of each agent on the others is “significant” regardless if cooperative of competitive (!economies)
● A.I.: deterministic, turn-taking, two-player, zero-sum games of perfect information.
	● Deterministic, fully observable, multi-agent environments (alternating actions)

Games in AI
● Early start: 1950
	● Chess: Konrad Zuse
	● Claude Shannon (information theory) 
	● Norbert Wiener (control theory)
	● Alan Turing
● Too hard to solve
	● Chess: b=35, 50 moves per player (d=100) 
	● ->35^100 approx. 10^153 nodes (only approx. 10^40 distinct nodes)
● -> Real world: must make some decision, even if impossible to make the optimal one
● -> Penalties if inefficient (thinking too much) 
● Solution:
	● Use pruning to reduce the search space 
	● Use heuristic evaluation functions to approximate the true utility of a state


Games vs. search problems
● "Unpredictable" opponent -> specifying a move for every possible opponent reply
● Time limits -> unlikely to find goal, must approximate
● Games that include an element of chance (rolling of dice)
● Games with imperfect information (hidden)


Games Classification

				Deterministic 				Chance
Perfect  		chess  					Backgammon
information 	checkers				Monopoly
				Go
				Othello

imperfect		Battleships 			Bridge
information 	Blind tic-tac-toe 		Poker
										Scrabble

Optimal Decisions in Games

Search Problem Formulation
● Initial State:
	● Board position
	● Player to move next
● Successor function:
	● f(crt_state) = List<Tuple<Move, State>> 
		● Move = a legal move allowed
		● State = the resulting state after the move
● Terminal test
	● Is the game over? (Terminal states)
● Utility function (objective function or payoff function) 
	● Assigns numeric values to terminal states
	● +1 (WIN), 0 (DRAW), -1 (LOSS)


Game Tree = initial state + the legal movecs for each side

Optimal Strategies
● Can we simply identify a sequence of moves leading to a goal state (WIN terminal state)?
	● NO, because of MIN
● -> MAX must identify a contingent strategy:
	● MAX’s move in the initial state
	● MAX’s moves in the states resulting from all possible moves of MIN
￼￼￼￼● MAX’s moves in the states resulting from every possible response by MIN to those moves, ETC
	● -> Game tree becomes too complex to draw

A two-ply game tree
-MAX nodes: MAX moves next
-MIN nodes: MIN moves next
-utility function value of a min node is the minimum value of its successors
-utility function value of a max node is the max value of its successors

Minimax
● Perfect play for deterministic games
● Idea: choose to move to a position with the highest
	minimax value = best achievable payoff against best play
● The minimax value of a node is the utility (for MAX) of being in the corresponding state
● Assumption: both players play optimally

Properties of Minimax
Complete? 		Yes :– if tree is finite
Optimal? 		Yes :– against an optimal opponent

Time 			O(bm)
complexity

Space 			O(bm) :– if all successors are 
					generated at once 
				O(m) :– if successors are generated 
					one at a time

b = average branching factor

● For chess, b ≈ 35, m ≈100 for "reasonable" games 	
	-> exact solution completely infeasible


Minimax for multi-player games
-utility = vector of values, one for each player
	-> modify the utility function (return vector with max value for current player)

Alliances
● Formal or informal
● Are made and broken as the game proceeds
● May be a natural consequence of optimal strategies for each player
	● Collaboration may emerge from purely selfish behavior
	● Agreements may be later violated 
● Explicit or implicit
	● There may exist a social stigma to breaking an alliance
	● -> Must balance the immediate advantage of breaking an alliance against the long-term disadvantage of being perceived as untrustworthy
● May occur even in a 2-ply game, if the game is not zero-sum
	● players may cooperate to achieve a mutually desired goal

Alpha-beta pruning
● Problem with Minimax:
	● Too many game states to examine 
		● Exponential in the number of moves
● Compute the correct minimax value/decision without looking at every node in the game tree
● Alpha-Beta pruning:
	● If applied to a minimax tree, returns the same move as minimax
	● Prunes away branches that cannot influence the final decision

alpha - beta pruning example - explained

MINIMAX-VALUE(root)
	= max(min(3,12,8), min(2,x,y), min(14,5,2)) 
	= max(3, min(2,x,y), 2)
	= max(3, z, 2) where z ≤ 2
	=3
The value of the root and the minimax decision are indepenent of the values of the pruned leaves x and y

Why is it called alpha - beta
● α is the value of the best (i.e., highest- value) choice found so far at any choice point along the path for MAX
● Ifvisworsethanα, max will avoid it
!prune that branch
● Define β similarly for
MIN

Transpositions
● Repeated states -> exponential increase in search cost 
● Frequent in games because of transpositions
	● =Permutations of the move sequence that end up in the same position
		● -> save the evaluation of a position in a hashtable (transposition table)

Imperfect, Real-Time Decisions

Resource limits

Suppose we have 100 seconds & explore 104 nodes/sec
	-> 106 nodes per move [] 358/2 -> alpha - beta reaches depth 8
		-> pretty good chess program
Standard approach:
	-cutoff text (instead of terminal-test)
		e.g., depth limit (perhaps add quiescence search)
	-evaluation function (intead of true utility)
		= estimated desirability of position (or features of a given state)


For chess typically weighted linear sums of features
	Eval(s) = w1f1(s) + w2f2(s) + ... + wnfn(s)

no chess problems on final

Cutting off search

MinimaxCutoff is identical to MinimaxValue except 
	1.	Terminal? is replaced by Cutoff?
	2. 	Utility is replaced by Eval 

Does it work in practice?
	b^m = 10^6, b=35 -> m=4

4-ply lookahead is a hopeless chess player!
	-4-ply ≈ human novice
	-8-ply ≈ typical PC, human master 
	-12-ply ≈ Deep Blue, Kasparov		

Exact Value vs. Order

● Behavior is preserved under any monotonic 
	transformation of EVAL
● Only the order matters, not the exact values!
● Payoff in deterministic games acts as an ordinal 
	utility function

Deterministic games in practice
● Checkers: Chinook ended 40-year-reign of human world champion Marion Tinsley in 1994. Used a pre-computed endgame database defining perfect play for all positions involving 8 or fewer pieces on the board, a total of 444 billion positions.
● Chess: Deep Blue defeated human world champion Garry Kasparov in a six-game match in 1997. Deep Blue searches 200 million positions per second, uses very sophisticated evaluation, and undisclosed methods for extending some lines of search up to 40 ply.
● Othello: human champions refuse to compete against computers, who are too good. The Logistello program (1997) defeated human champion Takeshi Murakami by 6:0
● Go: human champions refuse to compete against computers, who are too bad. In go (19x19), b > 300, so most programs use pattern knowledge bases to suggest plausible moves.


Element of Chance
● What if we don’t know what the result of an action will be?
	● Examples: solitaire, pacman, minesweeper, games involving dice rolls, ...
● Counting:
	● How many ways to roll 2 dice? ● How many unique ways?
	● Technique used: expectiminimax search ● Maximize the average score
● Chance nodes
	● Like MIN nodes, except the outcome is uncertain
	● Calculate expected utilities
	● MAX nodes, similar to minimax search


-------------------------------------------------------

Artificial Intelligence Lecture 9 Notes


Key Concepts
● Representation of knowledge 
● Reasoning processes
● Knowledge & Reasoning
	● Enable successful behavior
	● Dealing with partially observable environments
		● Infer hidden aspects of the current state 
	● Enable flexible behavior
		● Receive new tasks (explicitly described goals)
		● Achieve competence (learning)
		● Adapt to changes (updating relevant knowledge)


Knowledge bases
● Knowledge base = set of sentences in a formal language
● Declarative approach to building an agent (or other system):
	● TELL it what it needs to know
● Then it can ASK itself what to do - answers should
￼￼follow from the KB
-inference engine = domain-independent algorithms
-knowledge base = domain-specific content

A simple knowledge-based agent
	function KB-Agent(percept) returns an action
		static: KB, a knowledge base
				t, a counter, initially 0, indicating 
												time
		TELL(KB,Make-Percept-Sentence (percept,t))
		action<- Ask (KB,Make-Action-Query(t))
		TELL(KB,MAKE-ACTION-SENTENCE(action,t))
		t<- t+1
		return action

● The agent must be able to:
	● Represent states, actions, etc.
	● Incorporate new percepts
	● Update internal representations of the world
	● Deduce hidden properties of the world
	● Deduce appropriate actions		

The Wumpus World
-final will have describe PEAS for an agent in a particular world

Wumpus World PEAS Description
● Performance measure
	● gold +1000, death -1000
	● -1 per step, -10 for using the arrow
● Environment
	● Squares adjacent to wumpus are smelly
		-not including diagonal adjacent
	● Squares adjacent to pit are breezy
	● Probability that a square is a pit = 0.2
	● Glitter iff gold is in the same square
	● Shooting kills wumpus if you are facing it
		-you will hear a scream if he's killed
	● Shooting uses up the only arrow
	● Grabbing picks up gold if in same square
	● Releasing drops the gold in same square
● Sensors:
	● Stench, Breeze, Glitter, Bump, Scream
		-bump if you try to walk into wall
● Actuators:
	● Left turn, Right turn, Forward, Grab, Release, Shoot
	● Die if entering a square with a pit or a live wumpus


Wumpus world characterization
-know this for final
-fully observable?
	-no, only local perception
-deterministic?
	-yes - outcomes exactly specified
-episodic?
	-no - sequential at the level of actions
-static?
	-yes - wumpus and pits do not move
-discrete?
	-yes - not sure why maybe b.c. not unlimited size board?
-single-agent?
	-yes - wumpus is essentially a natural feature


Exploring a Wumpus World
-coordinates = (col,row) from bottom left corner = (1,1)
-first location you are at (bottom left) is safe
	|	 |	  |
----|----|----|----
	|	 |	  |
----|----|----|----
	|	 |	  |
----|----|----|----
  A	|	 |	  |
-no stench or breeze so above and to the right is okay
	|	 |	  |
----|----|----|----
	|	 |	  |
----|----|----|----
  A	|	 |	  |
----|----|----|----
  A	| A	 |	  |

-go up and sense breeze
	-you know pit above or to the right
	|	 |	  |
----|----|----|----
 P?	|	 |	  |
----|----|----|----
  A	| P? |	  |
----|----|----|----
  A	| A	 |	  |

-go back to starting point and go right instead
	-you sense a stench and no breeze
	-that means you know above is not a pit and to the right must be a wumpus

	|	 |	  |
----|----|----|----
  P	|	 |	  |
----|----|----|----
  A	|    |	  |
----|----|----|----
  A	| A	 | W  |

-so now move up
	-dont sense breeze or stench so we know above and right are safe

	|	 |	  |
----|----|----|----
  P	|	 |	  |
----|----|----|----
  A	| A  |	  |
----|----|----|----
  A	| A	 | W  |

-move to right
	-sense breeze, glitter, and stench (BGS)
	-wumpus below is stench, breeze means pit either above or to the right, and glitter means Im in a box with gold

	|	 |	  |
----|----|----|----
  P	|	 |	  |
----|----|----|----
  A	| A  | A  |
----|----|----|----
  A	| A	 | W  |

If we had gotten to 2,1 and sense breeze there also would have been no safe action
	-use probability of each 1 being a pit to know where to go

If in 1,1 there had been a stench then we would have had to use coercion strategy
	-shoot straight ahead
	-wumpus was there -> dead other wise move to other one since only 1 wumpus


Logic

Logic in general
● Logics are formal languages for representing information such that conclusions can be drawn
● Syntax defines the sentences in the language 
● Semantics define the "meaning" of sentences;
	● i.e., define truth of a sentence in a world
● E.g., the language of arithmetic
	● x+2 ≥ y is a sentence; x2+y > is not a sentence
	● x+2 ≥ y is true iff the number x+2 is no less 
						  than the number y
	● x+2 ≥ y is true in a world where x = 7, y = 1
	● x+2 ≥ y is false in a world where x = 0, y = 6

Entailment

● Entailment means that one thing follows from another:
KB ╞ α
● Knowledge base KB entails sentence α if and
only if α is true in all worlds where KB is true 
	● E.g., x + y = 4 entails 4 = x + y
		4 = x + y is true in all cases x + y = 4
	● Entailment is a relationship between sentences (i.e., syntax) that is based on semantics


Models
● Logicians typically think in terms of models, which are formally structured worlds with respect to which truth can be evaluated
● We say m is a model of a sentence α if α is true in m
● M(α) is the set of all models of α
● ThenKB╞α
iff M(KB) C_ M(α)

Entailment in the Wumpus World
	|	 |	  |
----|----|----|----
	|	 |	  |
----|----|----|----
  ?	| ?	 |	  |
----|----|----|----
  A	| A	 |	? |

● Situation after detecting nothing in [1,1], moving right, breeze in [2,1]
● Consider possible models for KB assuming only pits
● 3 Boolean choices =>
	8 possible models (2^3)
-KB = wumpus-world rules + observations
α_1 = "[1,2] is safe", KB ╞ α_1, proved by model checking
	- the knowledge base entails α_1 b.c. in all cases that the KB is true, α_1 is true

α_2 = "[2,2] is safe", KB does not ╞ α_2 b.c. in some cases of the KB α_2 is false

Logical Inference
● Definition:
	● = the process of deriving conclusions 
● Model checking
	● Inference algorithm based on enumerating all possible models to check that a sentence is true in all models in which KB is true.
	● Works if the space of models is finite 
	● Arithmetic ???
		● How many models are for the sentence x + y=4?

Inference
● KB ├i α = sentence α can be derived from KB by procedure i
● Consequences of KB are a haystack; α is a needle.
● Entailment = needle in haystack; inference = finding it
Inference algorithm (i):
● Soundness: i is sound if
	whenever KB ├i α , it is also true that KB╞ α
● Completeness: i is complete if
	whenever KB ╞ α , it is also true that KB ├i α
-preview: we will define a logic (first-order logic) which is expressive enough to say almost anything of interest, and for which there exists a sounds and complete inference procedure.
-that is, the procedure will answer any question whose answer follows from what is known by the KB

Reasoning
● If KB is true in the real world, then any sentence α derived from KB by a sound
inference procedure is also true in the real world.
● Sentences = physical configurations of the agent
● Inference operates on the syntax of sentences
● Reasoning = the process of constructing new sentences from old ones
	● Reasoning should ensure that the new configurations represent aspects of the world that actually follow from the aspects that the old configurations represent

Propositional Logic

Propositional Logic: Syntax
● Propositional logic is the simplest logic
● Syntax: defines allowable sentences
● The proposition symbols P1, P2 etc are sentences
● True and False proposition symbols
● If S is a sentence, 	-S is a sentence  (negation)
● If S1 and S2 are sent., S1^S2 is a sent.(conjunction)
● If S1 and S2 are sent., S1 downarrow head S2 is sent.
						  -(disjunction)
● If S1 and S2 are sent., S1 => S2 is a sent. 
							-(implication)
● If S1 and S2 are sent., S1 <=> S2 is a sent. 
							-(biconditional)

Propositional Logic: Semantics
●Each model specifies true/false for each proposition symbol 
	E.g. P_(1,2) P_(2,2) P_(3,1)
		 false 	  true    false
	-boolean representing true or false on if there is a pit at coordinates (1,2),(2,2), (3,1) respectively

● With these symbols, 8 possible models, can be enumerated automatically. (we did that earlier)
●Rules for evaluating truth with respect to a model m:
 -S (not S) is true iff S is false
 S_1 ^ S_2 (S_1 and S_2) is true iff S1=true & S2=true
 S_1 upside S_2 (S_1 or S_2) is true iff S1=true or 
 	 down									S2=true
 	 arrow
 	 head
 S_1=>S_2 (S_1 implies S_2) is true iff S_1=False or 
 									    S_2 is true
 	-the statement as a whole is true if S_1 is false or S_2 is true
 S_1 <=> S_2 is true iff S_1=>S_2 is true and 
 						 S_2=>S_1 is true
● Simple recursive process evaluates an arbitrary sentence (e.g.)
	-P_(1,2) ^ P_(2,2) or P(3,3)) = true and (true or false) = true and true = true

Truth Tables for Connectives
-know for final
P 	Q 	| -P   P^Q 	PorQ 	P=>Q 	P<=>Q
F   f      t    t    f       t        t
F   t      t    f    t       t        f
T   f      f    f    t       f        f
T   t      f    t    t       t        t

Wumpus World Sentences
● Let Pi,j be true if there is a pit in [i, j].
● Let Bi,j be true if there is a breeze in [i, j].
Not P_(1,1)
Not B_(1,1)
	B_(2,1)
● "Pits cause breezes in adjacent square"
	B_(1,1) <=> (P_(1,2) or P_(2,1))
	B_(2,1) <=> (P_(1,1) or P_(2,2) or P_(3,1))
● "A square is breezy iff there is an adjacent pit"

	|	 |	  |
----|----|----|----
	|	 |	  |
----|----|----|----
  ?	| ?	 |	  |
----|----|----|----
  A	| A	 |	? |

● Situation after detecting nothing in [1,1], moving right, breeze in [2,1]

Inference
● Goal of logical inference:
● To decide whether KB ╞ α
● One possible way:
	● To enumerate all models and check if α is T or F in every model in which KB is true
	● If the symbols are:
		● B11, B21, P12, P11, P22, P21, P31 (7 symbols)
	● Then we have 27 = 128 models
	● (Truth table) -> KB is true in 3 of these 128 models

Truth Tables for inference
-slide 37
-enumerate rows (different assignments to symbols), if KB is true in row, check that alpha is too

Inference of Enumeration
-Depth-first enumeration of all models is sound

Logical Equivalence
-2 sentences are logically equivalent iff true in same models
	alpha = B iff alpha ╞ B and B ╞ alpha
	-will provide this for final but would help to understand 
	-slide 39

Validity and Satisfiability
-on test to figure out if valid and/or satisfiable
● A sentence is valid if it is true in all models,
	● e.g. True, A or not A, A => A, (A^(A=>B))=B
● Validity is connected to inference via the Deduction Theorem:
 	KB ╞ alpha iff (KB => alpha) is valid
● A sentence is satisfiable if it is true in some model
	● e.g. A or B, C
● A sentence is unsatisfiable if it is true in no model
	● e.g. A ^ notA
● Satisfiability is connected to inference via the following:
	 KB ╞ alpha iff (KB and not alpha) is unsatisfiable

Reasoning Patterns in Propositional Logic

Inference Rules
● Patterns of inference used to derive chains of conclusions that lead to the desired goal
-modus ponens: alpha => B, alpha
				________________
					B

-and-elimination   alpha ^ B
				  ___________
				  	alpha

Proof - Wumpus World
-be able to do something like this on final
-sentences from KB
	R1 : not P_(1,1)
	R2 : B_(1,1) <=> (P_(1,2) or P_(2,1))
	R3 : B_(2,1) <=> (P_(1,2) or P_(2,1) or P_(3,1))
	R4 : Not B_(1,1)
	R5 : B_(2,1)
-proof that neither [1,2] nor [2,1] contains PIT
	R6 : (B_(1,1) => (P_(1,2) or P_(2,1))) ^
		 ((P_(1,2) or P_(2,1)) => B_(1,1))
    R7 : ((P_(1,2) or P_(2,1)) => B_(1,1))
    R8 : (NOT B_(1,1) => NOT(P_(1,2) or P_(2,1)))
    R9 : NOT(P_(1,2) or P_(2,1))
    R10: NOT P_(1,2) and NOT P_(2,1)  	q.e.d.

Resolution
-inference rule
-yields a complete inference algorithm when coupled with any complete search algorithm
-Wumpus World
	Agent: [1,1] -> [2,1] -> [1,1] -> [1,2] : {S,Not B}
	R11 : Not B_(1,2)
	R12 : B_(1,2) <=> (P_(1,1) or P_(2,2) or P_(1,3))
	R13 : Not P_(2,2)
	R14 : Not P_(1,3)
	R15 : P_(1,1) or P_(2,2) or P_(3,1)
	R16 : P_(1,1) or P_(3,1)
	R17 : P_(3,1)


Complimentary literals
 (P_(1,1) or P_(1,3)) and Not P_(1,1)
 P_(1,3)
-the resulting clause should contain only 1 copy of each literal -> factoring
-sound and complete when using a complete search algorithm
	-can derive any conclusion entailed by any KB in propositional logic
-applies only to disjunctions of literals

Conjunctive normal function (CNF)
● Every sentence of propositional logic is logically equivalent to a conjunction of disjunctions of literals
● Conjunctive Normal Form (CNF - universal) 
	● conjunction of clauses (clause = disjunctions of
￼￼￼literals)
		E.g. (A or Not B) AND (B or Not C or Not D)
			P_(1,3) or P_(2,2), Not P_(2,2)
			_______________________________
						P_(1,3)


Conversion to CNF
-starting with 	R2 : B_(1,1) <=> (P_(1,2) or P_(2,1))
	1. Eliminate <=>, replacing a<=>B with 
										(a=>B)^(B=>a)
    	-> (R6)
    2. Eliminate => replace a=>B with (Not a) or B
    	((Not B_(1,1))or (P_(1,2) or P_(2,1))) AND 
    	( (Not (P_(1,2) or P_(2,1))) or B_(1,1)) 
    3. Move Not inwards using demorgan's rules and double negation
       	((Not B_(1,1))or (P_(1,2) or P_(2,1))) AND 
		( (NotP_(1,2) and  NotP_(2,1)) or B_(1,1)) 	
	4. Apply distributivity law (and over or) and flatten
		(NotB_(1,1) or P_(1,2) or P(2,1)) and 
		(NotP_(1,2) or B_(1,1)) ^ (NotP_(2,1) or B_(1,1))

Foward and BackWard Chaining
-having at most one positive is faster
-Horn form (restricted representatino form of a clause)
	-KB = conjunctino of Horn clauses

	Horn clause = disjunctino of literals
				  at most one literal is positive

	-Modulus Ponnens (for Horn Form): complete fror Horn KBs
		alpha1,..,alphan, alpha1^...^alphan => B
		_________________________________________
							B
	-can be used with forward chaining and backward chaining
	-these algorithms ar very natural and run in linear time
		(relative to the KB size)

Forward Chaining
-slide 50s
-Data-driven reasoning
-idea
	-fire any rule whose premisses are satisfied in KB
	-add its conclusion to the KB, until query is found

-every literal is a node in the graph
	-and is arc
	-start from bottom and try to make it up till Q is true

-Backward training
	-goal driven
	-more effective
	-starts with conclusion (Q) and goes down graph and then back up to see what is necessary for Q to be true

Forward vs. Backward Chaining
-data-driven vs goal driven
-fd may do lots of work irrelevant to goal


Inference based agents in the wumpus world
-a wumpus-world agent using propositional logic:
....

Midterm walk through 
Problem 1. 
	Books adopts intelligent agent approach 
	c. Acts rationally
Problem 2.
	d. DFS is incomplete
	e. false -> BFS is complete as long as the branching factor...
	g. true DFS is an improvement over BFS w.r.t memory
	j. False -greedy best search is optimal
Problem 3.
	 b. if all queens in 1 row then all queens attack each other
	 	- so the distinct attacks order of pair doesn't matter
	 	-all in same row - 10=4+3+2+1
problem 4.
	a.iii. IDS - numerous sets when searching - one search set for each depth level
problem 5.
	- A* search problem on final
problem 6.
	- a. maximum number of non-attacking distinct pairs in the n-queens problem is :
	n choose 2 = n/(2!(n-2)!)= 16 for 6 queens problem

-------------------------------------------------------

Artificial Intelligence Lecture 10 Notes


First-Order Logic

Knowledge Representation

Pros and Cons of Propositional Logic
-pros
	-declarative
		-pieces of syntax correspond to facts
	-allows partial/disjunctive/negated information
		-unlike most data structures and databases
	-propositional logic is compositional
		-meaning of B_(1,1) ^ P_(1,2) is derived from meaning of B_(1,1) and of P_(1,2)
	-meaning in propositional logic is context-independent
		-unlike natural language, where meaning depends on context
-con
	-unlike natural language: B_(1,1) <=> 
									(P_(1,2)orP_(2,1))
	-E.g. cannot say "pits cause breezes in adjacent squares"
		-except by writing one sentence for each square

First-Order Logic
-propositional logic assumes the world contains facts, as oppposed to
-first-order logic (like natural language), which assumes the world contains
	-objects: peoples, houses, numbers, colors, baseball games, wars
	-relations/properties:red, round, prime, brother of, bigger than, part of, comes between...
	-functions: father of, best friend, one more than, plus, ...

Logics in general
	-ontological commitment
		-what it assumes about the nature of reality
	-epistemological commitment
		-the possible states of knowledge that it allows w.r.t each fact

Syntax & Semantics

Models for First-Order Logic
-models for a logical language

Example

Truth in first-order logic
-sentences are true w.r.t. a model and an interpretation
-model contains objects (domain elements) and relations among them
-interpretation specifies referents for
	-constant symbols -> obejcts
	-predicate symbols-> relations
	-function symbols-> functional relations
-an atomic sent. predicate (term1,...termn) is true iff the objects referred to by term1,...,termn are in the relation referred to by predicate

Syntax of FOL: Basic Elements
-constants KingJohn,2,SMU
-predicates Brother>,OnHead,King
-Funcitons sqrt,LeftLegOf,...
-variables x,y,a,b
-connectives not, and, or, <=>,=>
-equality =
-quantifiers there exists, for all

Atomic Sentences
-atomic sentence 	= predicate (temr1,..termn)
-term 				= function(term1,...termn) or 
						constant or variable
Example:
	Brother(KingJohn,RichardTheLionHeart)
	Married(Mother(Richard),Father(John))

-atomic sentences state facts
-an atomic sentence is true in a given model, under a given interpretation, if the relation referred to by the predicate symbol holds among the objects referred to by the arguments

Truth Example
-consider the interpretation in which
	Richard-> Richard the Lionheart
	John->the evil King John
	Brother->the brotherhood relation
-under the interpretation, Brother(Richard,John) is true just in case Richard the Lionheart and the evil King John are in the brotherhood relation in the model

Complex Sentences
-complex sentences are made from atomic sentences using connectives
	Not S, S1 ^ S2, S1 or S2, S1 => S2, S1 <=> S2
-Examples:
	Sibling (KingJohn,Richard)=> Sibling(Richard, KingJohn)
		NOT Brother(LeftLeg(Richard,John))
		King(Richard) or King(John)

Universal Quantification
-For all..
-For all x at(x,SMU) => Smart(x)
-for all x P is true in a model m iff P is true with x being each possible object in the model
-Roughly speaking, equivalent to the conjunction of instantiations of P
	
A Common to Mistake to Avoid
-typically, => is the main connective with For All
-Common Mustake: using ^ as the main connective with for all
		For All x At(x,SMU) ^ Smart(X)
		-means everyone is at SMU and everyone is smart

Existential Quantification
-There exists <sentence>
there exists x At(x,SMU) ^ Smart(x)
	-there exists x at smu s.t. x is smart
-there exists x P is true in a model m iff P is true with x being some possible object in the model

Another Common Mistake to Avoid
-typically, ^ is the main connective with there exists
-common mistake: using => as the main connective with there exists:
	There exists x At(x,SMU) => Smart(x)
		is true if there is anyone who is not at SMU

Nested Quantifiers
	-Forall X For all y is the same as For all Y forallx
	-there exists X there exists y is the same as there exists Y there exists x
	-there exists x for all y is not the same as for all y there exists x
	-there exists x for all y Loves(x,y)
		-There is a person who loves everybody in the world
	-for all y there exists x Love(x,y)
		-everyone in the world is loved by at least one person
-quantifier duality: each can be expressed using the other
	For all x Likes(x,Icecream)
		Not there exists X not Likes(x,Icecream)
	There exists x Likes(x,Broccoli)
		-Not For all x Not Likes(x,Broccoli)

Equality
 term1 = term2 is true under a given interpretation iff term1 and term2 refer to the same object
 -E.g. Father(John) = Henry
 -E.g. definition of Sibling in terms of Parent:
 		For all x,y Sibling(x,y) <=>
 		[Not(x=y)^ there exists m,f Not(m=f)^Parent(m,x)^ Parent(f,x)^PArent(m,y)^Parent(f,y)]


Interacting with FOL KBs
-suppose a wumpus-world agent is using an FOL KB and perceives a smell and a breeze (but no glitter) at t=5

Assertion 	Tell(KB, Percept([Smell,Breeze,None],5))
Query 		Ask(KB, there exists a BestAction(a,5))
	-quantified query

-i.e. does the KB entail some best action at t=5
-answer: yes
	{a/shoot} <- substitution (binding list)
-given a sentence S and a substitution sigma, Ssigma denotes the result of plugging sigma into S. e.g.
		S = Smarter(x,y)
		sigma = (x/Tom,y/Jerry)
		Ssigma = Smarter(Tom,Jerry)
-Ask(KB,S) returns some/all sigma s.t. KB ╞ Ssigma

The kinship Domain
	-Brothers are siblings
		For all x,y Brothers(x,y)=> Siblings(x,y)
	-"Sibling" is symmetric
		For all x,y Sibling(x,y) <=> Sibling (y,x)
	-One's mother is one's female parent
		For all x,y Mother(y,x)<=>Female(x)^Parent(x,y))
	-a first cousin is a child of a parent's sibling
		For all x,y FirstCousin(x,y)<=>There exists p, ps Parent(p,x)^Sibling(ps,p)^Parent(ps,y)

-know how to represent sentences in FOL for final

KB for the Wumpus World
-[A] Perception
	for all t,s,b Percept([s,b,Glitter],t)=>Glitter(t)
	for all t,g,b Percept([Stench,b,g],t)=>Stench(t)
-[B] Action
	-Turn(right), Turn(Left), Forward, Grab, Release, Shoot
-Reflex
	-For all t Gliter(t) => Action(Grab,t)
-Reflex with internal state: do we have the gold already?

Deducing Hidden Properties
-[C] Environment (Locations)
	For all x,t At(Agent, x,t)^Stench(t) => Smelly(x)
	For all x,t At(Agent, x,t)^Breeze(t) => Breezy(x)
	(no time argument -> diachronic sentence)
-squares are breezy near  apit
	-Diagnostic
		rule -> infer cause from effect
		for all y Breezy(y) => there exists x Pit(x)^Adjacent(x,y)
	-Causal
		rule -> infer effect from cause
			For all x,y Pit(x) and Adjacent(x,y)=>Breezy(y)
		-model-based reasoning systems
-neither rule (diagnostic or causal) is complete
	-e.g. the causal rule doesn't say whether squares far away from pits can be breezy
-definition of breezy
	forall y Breezy(y) <=> [There exists xPit(x) ^ Adjacent(x,y)]

Keeping track of change
-facts hold in situations, rather than eternally
	-e.g. Holding(Gold,Now) rather than just holding(gold)
-Situation Calculus is one way to represent change in FOL:
	-adds a situation argument to each non-eternal predicate
	-e.g. Now in Holding(Gold,Now) denotes a situation
-situations are conbnected by the result function
-result(a,s) is the situation that results from doing a in s

Knowledge Engineering
- = process of building KB
-Process components
	-investigating a particlar domain
	-identify concepts
	-create formal representation of the objects and relations in the domain (Assocation)
-knowledge bases:
	-special-purpose
		-bounded domain
		-known range of queries
	-general-purpose
		-queries covering the fullrange of human knowledge

Automatic Identification and Analysis of Websites Selling Counterfeit Goods

AI in Mass Media

-------------------------------------------------------

Artificial Intelligence Lecture 11 Notes


Inference in First-Order Logic
-FOL can be used to state pretty much anything
	-it may be hard, but not impossible
	-use universal quantifiers

Universal Instantiation (UI)
-every instantiation of a universally quantified sentence is entailed by it:
		
			FORall v 	alpha
		________________________
			SUBST ({v/g},alpha)
for any variable v and ground term g(= a term w.o variables)

Example:
Forall x King(x) ^ Greedy(x) => Evil(x) yields:
	King(John) ^ Greedy(John) => Evil(John)
	King(Richard) ^ Greed(Richard) => Evil(Richard)
	King(Father(John)) ^ Greedy(Father(John))=>
						Evil(Father(John))

Existential Instantiation (EI)
-for any sentence alpha, variable v, and constant symbol k that does not appear elsewhere in the knowledge base:
		
			There exists v alpha
		____________________________
			SUBST({v/k}, alpha)
-means substitifution of variable with ground term into alpha

-Example
	From the sentence
		there exists(x)  Crown(x) ^ OnHead(x,John)
	we can infer the sentence:
		Crown(C1) ^ OnHead(C1,John)
	provided C1 is a new constant symbol, called a Skolem constant


	UI and EI
-UI can be applied several times to add new sentences:
	-the new KB is logically equivalent to the old
-EI can be applied once to replace the existential sentence:
	-the new KB is not equivalent to the old, but it satisfiable iff the old KB was satisfiable
		== inferentially equivalent
	-the knowledge bases aren't the same, but what you can infer is the same

Reduction to Propositional Inference
-Suppose the KB contains just the following
	Forall(x) King(x) ^ Greedy(x) =>Evil(x)
	King(John)
	Greedy(John)
	Brother(Richard,John)
-Instantiating the universal sentence in all possible ways, we have:
	King(John) ^ Greedy(John) => Evil(John)
	King(Richard) ^ Greedy(Richard) => Evil(Richard)
	King(John)
	Greedy(John)
	Brother(Richard, John)
-the new KB is propositionalized: proposition symbols are King(John), Greedy(John), Evil(John),Brother(John,Richard) etc.

-entailment in FOL is semidecidable
	-if it is entailed the answer will exist, but if it isn't you may be looking forever for proof that it isn't entailed


Problems with Propositionalization
-propositionalization generates lots of irrelevant sentences

Example:
Forall(X) King(X) ^ Greedy(X) => Evil(X)
King(John)
Greedy(John) 			or ForAll(Y) Greedy(Y)

-it seemds obvious that Evil(John), but propositionalization produces lots of facts such as Greedy(Rciahrd) that are irrelevant
-with p k-ary predicates and n constants, there are p*n^k instantiations

-1 variable with 3 values then you can produce 3 sentences

variables p1,p2,...,pk
-each of these could have values from 1..n
-k variables with n options/variables =n^k sentences
-analogy is 3 bits so 8 possible combinations

Generalized Modus Ponens (GMP)
-GMP used with KB of definite clauses (Exactly one psoitive literal)
-All variables assumed universally quantified
-GMP - a lifted version of MP:PL -> FOL

Unificiation
-we can get the inference immediately if we can find a substitution 0 s.t. King(x) and Greedy(x) match King(John) and Greedy(y)

theta = {x/John,y/John} works
Unify(alpha,Beta) = theta if alpha theta = beta theta

-find a combination of substititions that makes both sentences true
-standardizing apart:  eliminates overlap of variables, e.g. don't have variables represent different parts of different sentences


Forward Chaining (FOL)
Basics
	STeps
	1. Start with atomic sentences in the KB
	2. Apply Modus Ponens Forward
	3. Add new atomic sentence

	-Desirable to have only definite clauses
		-cause => Effect
		-Situation=> Response
	-Definite Clauses =
		-disjunctions of literals of which exactly one is positive
		-atomic or implication whose antecedent is a conjunction of positive literals and having a single positive literal consequent

Example Knowledge Base
-the law says it is a crime for an American to sell weapons to hostile nations. The country Nono, an enemy of America, has some missiles, and all of its missiles were sold to it by Colonel West, who is American

-Prove: Col. West is a criminal
-Approach: represent the KB facts as first-order definite clauses

-it is a crime for an American to sell Weapons to hostile weapons..
	American(x) ^ Weapon(y) ^ Sells(x,y,z) ^ Hostile(z) => Criminal (x)

-Nono.. has some missiles, i.e., thereExists(x) Owns(Nono,x) ^ Missile (x) : 
	Owns(Nono,M1) ^ Missile(M1)
-All of its missiles were sold to it by Colonel West
	Missile(x) ^ Owns(Nono,x) => Sells(West,x,Nono)
-Missiles are weapons
	Missile(x) => Weapon(x)
-An enemy of America Counts as "Hostile"
	Enemy(X,America) => Hostile(X)
-west who is american...
	American(West)
-The country Nono, an enemy of America...
	Enemy(Nono,America)

-building a tree going upwards




Properties of Forward Chaining
-Sount and complete for first-order definite clauses

Hard Matching Example
-trying to determine if map is colorable
-Colorable() is inferred iff the CSP has a solution
-CSPs include 3SAT as a special case, hence matching is NP-hard

Backward Chaining Example
-start with conclusion and work down to facts

Logic Programming
-computatio as inference on logical KB
-Should be easier to debug Capital (New York, US) than x:=x+2

Logic Programming: Prolog
-Basis: backward chaining w.Horn clauses + bells & whistles
	Widely used in Europe, Japan (basis of 5th generation project)

Program = set of clauses = head:-leteral1,...,literaln


Conjunctive Normal Form for FOL
-CNF - Conjunctive Normal Form
	-the conjunction of cluases, each clause being represented as a disjunction of literals
		-literals can contain universally quantified variables
-know how to transform propositional logic or first order logic sentences into the conjunctive normal form
	-can use proof by contradiction, inference by resolution to prove conclusions
-Example on slide 47
-every sentence in FOL can be converted to CNF

CNF
-CNF sentence will be unsatisfiable just when the orgiinal sentence is unsatisfiable (FAlse)
	-> basis for doing proofs by contradiction on the CNF sentences
-resolution proves that KB |= alpha by proving KB ^ not alpha unsatisfiable, i.e. by deriving empty clause

Conversion to CNF
-example on slide 49
-walk through this by hand
-remember steps and process, because we won't be given the steps for final

Conjuctive normal forms is a conjunction of disjunctions

Resolution Proof: Definite Clauses


know how to convert knowledge base into CNF for final

---------------
Presentations

Emulation of Human behavior in Virtual GAmes:
	The A* Pathfinding Algorithm
-Taylor Bishop

Soliving Einstein's Puzzle with Prolog
-Mike Shem

Prolog 
-declarative programming

Prolog Queries
-Declarative statements that evaluate to true or false
	-if it finds an assignment it prints it0
-cool b.c. you don't have to tell it how to solve Einstein's puzzle, you just give it facts and it comes up with solution

Evolution of AI in Modern Video Games


-------------------------------------------------------

Artificial Intelligence Lecture 12 Notes

Knowledge Representation

Ontological Engineering
-how to create more general and flexible representations
	-concepts like actions, time, physical object and beliefs
	-operates on a bigger scale than K.E.
-Define general framework of concepts 
	-upper ontology
-Limitations of logic representation
	-Red, green and yellow tomatoes: exceptions and uncertainty

Web Ontology Language (OWL)
- a way of structuring information

Difference with Special-Purpose Ontologies
-general-purpose should be applicable in any special-purpose domain

Categories and Objects
-similar to OOP design strategy
-interaction happens at object level
-reasoning at the category level
-categories play a role in predictions about objects
	-based on perceived properties
-Categories can be represented in 2 ways by FOL
	-predicates: apple(x)
	-reification of categories into objects: apples

Category Organization
-relation = inheritance
	- all instances of food are edible, fruit is a subclass of food and apples is a subclass of fruit then an apple is edible
-defines a taxonomy

FOL and categories
-an object is a member of a category
	-memberOf(BB12.Basketballs)
-a category is a subclass of another category
	-subsetOf(Basketball.Balls)
-All members of a categroy have some properties
	-for all x (MemberOf(x,Basketballs)=>Round(x))
-All members of a category can be recognized by some propertires
	-for all x (Orange(x)^Round(x)^Diameter(x)=9.5in^
				MemberOf(x,Balls)=>
							MemberOf(x,Baskebtalls))
-a category as a whole has some properties
	-memberOf(Dogs,DomesticatedSpecies)

RElations b.w. Categories
-2 or more categories are disjoint if they have no members in common
	- if intersection is empty
	-example: Disjoint({animals,vegetables})
-a set of categories s consitutes an exhaustive decomposition of a category c if all members of the set c are covered by categories in s:
	-E.D. (s,c)<=> (for all i  i inc in C => there exists C2 c2 included in s ^ i included in c2)
	-ex:
		ExhaustiveDecomposition({Americans,Canadian,Mexicans},NorthAmericans)

- a parittion is a disjoiint exhaustive decomposition
	-Partition(s,c)<=> Disjoint(s) ^ E.D.(s,c)
	-Ex:
		Partition({Males,Females},Persons)
-is({Americans,Canadian,Mexicans},North American) a partition?
	-not necessarily- could be mexican american, so there would be overlap so not a partition
-Categories can be defined by providing necessary and sufficient conditions for membership
	-for all x Bachelor(x) <=> Male(x) ^ Adult(x) ^ Unmarried(x)

Natural Kinds
-Many categories have no clear-cut definitions (chair bush,book)
-tomatoes: sometimes green, red, yellow, black, mostly round
-One solution: category Typical(Tomatoes)
	For all x, x included Typical(Tomatoes)=>Red(x)^spherical(x)
-can then treat exceptions separately

Physical composition
-one object may be part of another
	-PartOf(Bucharest,Romania)
-the PartOf predicate is transitive
-often characterized by structural relations among parts

Measurements
-objects have height, mass,cost, etc..
VAlues that we assign to these are measures
-combine unit functions with a number:
	Length(L1) = Inches(1.5) = Centimeters(3.81)
-Conversion b.w. units
	For all i Centimeters(2.54*i) = Inches(i)
-some measures have no scale
	-beauty, Difficulty, etc.
-most important aspect of measures is that they are orderable
	-don't care about the actual numbers (an apple can have deliciousness .9 or .1)

Actions, Situations, Events

Actions, Events, Situations
-reasoning about outcome of actions is central to KB-agent
-how can we keep track of location of FOL?
	-remember the multiple copies in PL
-representing time by situations (states resulting from the execution of actions)
	-situational calculus)

-situational calculus
	-actions are logical terms
	-situations are logical terms consisting of
		-the intnial situation i
		-all situations resulting from the actions on i
	-fluent are functions and predicates that vary from one situation to the next
		-E.g. Holding(G1,S0)
	-eternal predicates are also allowed
		-E.g. Gold(G1)
-projection task: an SC agent should be able to deduce the outcome of a sequence of actions

Result(action,situation)

Metnal Events and Objects
-relationships b.w. agents and mental objects:
	believes, knows, wants...
	-Believes(Lois,Flies(Superman)) with Flies(Superman) being a function... a candidate for a mental object (reificiation)

The Internet Shopping World
-knowledge engineering example
-an agent taht helps a buyer to find product offers on the internet
	-IN = product description (precise or not precise)
	-OUT = list of webpages that offer the product for sale
-Environment = WWW
-Percepts = web pages (character strings)
	-extracting useful information required

-Find relevant product offers
	-RelevantOffer(page,url,query)<=> Relevant(page,url,query) ^Offer(page)
-write axioms to define Offer(x)
-find relevant pages: Relevant(x,y,z)
	-start from an intiail set of stores
	-what is a relevant category?
	-what are relevant connected pages?
-require rich category vocabulary
	-synonymy and ambiguity
-how to retrieve pages: GetPage(url)
	-procedural attachment
-compare offers (information extraction)

Reasoning Systems for Categories
-how to organize and reason with categories?
	-semantic networks
		-visualize knowledge-base
		-efficient algorithms for category membership inference
	-description logics
		-formal language for constructing and combining category definitions
		-efficient algorithms to decide subset and superset relationships b.w. categories

Semantic Networks
-logic vs. semantic networks
-many variations
	-all represent individual objects, categories of objects and relationships among objects
-allows for inheritance reasoning
	-female persons inherit all properties from person
	-compare to OO programming
-inference of inverse links
	SisterOf vs. HasSister
-Drawbacks
	-links can only assert binary relations
	-can be resolved by reification of the proposition as an event
-representation of default values
	-enforced by the inheritance mechanism

Description logics
-are designed to describe definitions and propertires about categories
	-a formalization of semantic networks
-principle inference tasks are:
	-subsumption: checking if one category is the subset of another by comparing their definitions
	-classification: checking whether an obejct belongs to a category
	-consistency: whether the category membership criteria are logically satisfiable

Conceptual Model Example
-should be able to build
-draw categories and relationships b.w. the categories
-like OOP designs
-remember cardinality
	-1 to many, many to 1, or many to many
		Ex. *,1,1.*
			0 to many, 1, 1 to many

		Ex: 				<<use>>
			File Manager ----------> Configuartion 
				|						Manger
				|						(static class)
				|_______________________|^


		<<>> means stereotype
		<<use>> means fileman uses config manager


Introduction to Probability


Sample Space
-statistical data
	-experimental data
		-counts (counting)
		-measurements
	-categorical data
		-labeled/classified data rather then numerical
-observation
	- = any recording of information (numerical or categorical)
		-e.g. the numbers 2,0,1,1 representing the numbers of accidents that occurred at the interestion of binkley and smu blvd from january through april 2010
-Experiment
	-any process that generates a set of data
		-e.g. tossing a coin, or pair of dice, etc.
		-outcomes from these experiments = ?
-sample sapce (S)
	- = the set of all possible outcomes of a statistical experiment
-element (or member, or sample point)
	-an outcome in a sample space (S)
-S - finite or infinite
-coin tossing S = {H,T}
-Die tossing S1 = {1,2,3,4,5,6}
			 S2 = {even,odd}


Sample Space - statement/rule
-if S is very large or infinite
	-S is better described by a statement or rule
-Ex:
	-S = { x | x is a city with a population > 1 mill}
	-S = {(x,y) | x^2 + y^2 <=4}

Events
-Event
	-a subset of a sample space
-Ex #1
	-given S = {t | t>=0}, where t = life (in years) of a certain electronic component
	-then, the event A that the component fails before the end of the fifth year, is the subset
	-A = {t | 0 <= t < 5}
-Intersection of events
	A n B = the event containing all elements that are common to A and B
	-Ex:
		M = {a,e,i,o,u} N = {r,s,t} M n N = null
		-mutually exclusive
-Union of events
	 A u B = the event containing all the elements that belong to A or B or Both
	 -Ex: 
	 	A = {a,b,c} B={b,c,d,e}->A u B = {a,b,c,d,e}

Couting Sample Points
-counting (w.o listing) the sample points -> multiplication rule:
	- (thm): Multiplication rule
		if an operation can be performed in n1 ways, and if for each of these a second operation can be performed in n2 ways, then the 2 operations can be performed together in n1*n2 ways
	-Ex #1:
		# sample points when a pair of dice is thrown once? 
			n1*n2 = 6*6 = 36 possible ways
	-Ex #2
		# possible lunches if we select from 4 soups, 3 kinds of sandwiches, 5 desserts, and 4 drinks?
			4*3*5*4 = 240
	-Ex #3
		how many even 3-digit numbers can be formed from the digits 1,2,5,6,9 if each digit can be used only once?
		units n1=2 {2,6}
		tens n2 = 4 {1,5,9,(2 or 6)}
		hundreds: 3 {the 4 from tens minus what was actually used for tens}
		2*4*3 = 24 possible ways

Permutations
	-arrangements of all pairs of a set of objects
		-the number of permutations of n distinct objects is n!
		-the # of permutations of n distinct objects arranged in a circle = (n-1)!
		-the # of distinct permutations of n things of which n1 are of 1 kind, n2 are a second kind... - n!/(n1!*n2!*..*nk!)
Combinations
	-# of ways of selecting k objects from n without regard to order: (n)       n!
					 ( ) = _________
					 (k) 	k!(n-k)!


Probability of an event
-the sum of probabilities of each sample point in S should be 1
-Ex:
	toss a coin twice
	S = {HH,HT,TH,TT}
	A = the event of at least 1 head occurring
	A = {HH,HT,TH}
	P(A) = 3/4

-Ex:
	A loaded die: an even number is 2x as likely to occur as an odd number
	 if E = the event that a # < 4 occurs on a single toss of the die. P(E) = ?
	 E = {1,2,3} -> P(E) = 1/9 + 2/9 + 1/9 = 4/9

	 P(A u B) = P(A) + P(B) - P(A n B)

Poker example
	-in a poker hand consisting of 5 cards, find the probability of holding 2 aces and 3 jacks:
	-ways of dealing 2 Aces: 4 C 2 = 4!/(2!*2!) = 6
	-ways of dealing 3 jacks: 4C3 = 4!/(3!*3!) = 4
	-6x4 = 24 hands containing 2 aces and 3 jacks
	-total # of 5-card poker hands:
		-(equally likely hands)  52 C 5 = 
										52!/(5!*47!)
									=2,598,960
	P(2 aces and 3 jacks) = 24/2,598,960 = .9*10^-5

Additive Rule
-goal: computing event probabilities from known probabilities of other events
-additive Rule of probability:
	P(A u B) = P(A) + P(B) - P(A n B)
	if A and B are mutually exclusive you don't need the 3rd term

Conditional Probability

P(B|A) = the probability of an event B occuring when it is known that some event A has occurred

	P(B|A) = P(A n B)/ P(A) if P(A) > 0


Independent Events
-Events A and B are independent iff
	P(A|B) = P(A) and P(B|A) = P(B)
-multiplicative rule
	-the probability that 2 events will both occur
	P(A n B) = P(A) x P(B|A) =
	P(B n A) = P(B) x P(A|B)
-2 events A & B are independent iff
	P(A n B) = P(A) x P(B)

Bayes' Thm - simplified
-Conditional probability
	P(A|B) = P(A n B) / P(B)
-joint probability
	P(A n B) or P(A,B)
-Marginal probability
	P(A) regardless of B
-Prior probability
	P(A|I) I = initial information
-Posterior probability
	P(A | B, I) = updated probability of A, given I and the outcome of the event B
-Bayes' Thm: P(B|A) = P(A|B)* P(B)
							  ____
							  P(A)


Random Variables
-the field of statistics is concerned with  making inferences about populations and population characteristics
-experiments-> results that are subject to chance
-binary random variables, numeric, discrete, continuous

Presentation--------

Object/Facial Recognition

-------------------------------------------------------

Artificial Intelligence Lecture 13 Notes

Uncertainty
-Let action A1 = leave for airport t minutes before flight
Will A get there on time

Problems:
1. partial observability (road state, other drivers' plans, etc.)
2. noisy sensors (Traffic reports)
3. uncertainty in action outcomes (flat tire, etc.)
4. immense complexity of modeling and predicting traffic

Hence a purely logical approach either
	1. risks falsehood: A25 will get me there on time or
	2. leads to conclusions that are too weak for decision making
	"A25 will get me there on time if theres no accident on the bridge and it doesn't rain and my tires remain intact etc. etc."

	(A1440 might reasonabley be said to get me there on time but I'd have to stay overnight in the aiport...)

Methods for handling uncertainty
-default or non-monotonic logic:
	-Assume my car does not have a flat tire
	-Assume A25 works unless contradicted by evidence
-Issues: what assumptions are reasonable? how to handle contradiction

rules with fudge factors:
	A25 |->.3 get there on time
	Sprinkler |->.99 WetGrass
	WetGrass |-> .7Rain
-issues: problems with combination e.g. Sprinkler causes RAin??

-probability: models the agent's degree of belief:
	-Given the available evidence
		A25 will get me there on time with probability .04

Probability
-Probabilisitc assertions summarize effects of
	laziness
		-failure to enumerate exceptions, qualifications, etc.
	ignorance
		-lack of relevant facts, initial conditions, etc.

subjective or bayesian probability:
	-probabilities relate propositions to agent's own state of knowledge
		e.g. P(A25| no reported accidents) = .06
	-these are not assertions about the world (but might be learned from past experience of similar situations)
	-probabilities of propositions change with new evidence:
		e.g. P(A25 | no reported accidents, 5am) = .15

making decisions under uncertainty
-suppose I believe the following:
	P(A25 gets me there on time |...) = .04
	P(A90 gets me there on time | ...) = .7

-which action to choose
-depends on my preferences for missing flight vs. time spent waiting, etc.
	-utility theory is used to represent and infer preferences
	-decision theory = probability theory + utility theory

Syntax
-basic element: random variable (capitalized)
	= "Part" of the world whose "Status" is initially unknown
-Boolean random variable
	-Cavity (do I have a cavity?) <true,false>
-Discrete random variables
	e.g. Weather is one of <sunny,rainy,cloudy,snow>
-continuous random variables
	-not on final

Syntax
-atomic event
	-a complete specification of the state of the world about which the agent is uncertain
	E.g. if the world consists of only 2 boolean variables Cavity and Toothache, then there are 4 distinct atomic events
	Cavity = false ^ toothache = false
	Cavity = true ^ toothache = false
	Cavity = false ^ toothache = true
	Cavity = true ^ toothache = true

2*2 possible events

if weather with 4 was added then
2*2*4 = 16 possible events
-atomic events are mutually exclusive and exhaustive

Prior Probability
-prior or unconditional probabilities of propositions
	e.g. P(Cavity = true) = .1 and P(Weather = sunny) = .72
	correspond to belief prior to arrival of any (new) evidence
-prior Probability distribution gives values for all possible assignments.
	P(Weather) = <.72,.1,.08,.1> (normalized i.e. sums to 1)
-joint probability distribution for a set of random variables gives the probability of every atomic event on those random variables
	P(Weather,Cavity) = a 4x2 matrix of values:
-Every question about a domain can be answered by the joint distribution because every event is a sum of sample points.

Conditional Probability
-conditional or posterior probabilities
	e.g. P(cavity | toothache) =.8

	i.e. given that toothache is all I know
	NOT "if toothache then 80% chance of cavity"
-notation for conditional distributions:
	P(Cavity | Toothache) = 2 element vector of 2 element vectors
-if we know more e.g. cavity is also given, then we have P(Cavity | toothache, cavity) = 1
-new evidence may be irrelevant, allowing simplification:
	P(cavity | toothache, sunny) = P(cavity|toothache)
								 = .8
-this kind of inference, sanctioned by domain knowledge, is crucial

product rule
P(a^b) = p(a|b)*P(b) = P(b|a)*P(a)

A general version holds for whole distributions e.g. 
	P(Weather,Cavity) = P(Weather | Cavity) P(Cavity)
		-(View as a set of 4x2 equations not matrix multiplication)
Chain rule is determined from successive application of product rule

Probabilistic inference by enumeration
-start with the joint probability distribution
-for any proposition phi sum the atomic events where it is true: P(phi) = sum P(atomic events)

P(toothache) = .108 + .012 + .016+.064 = .2

Normalization
-denominator can be viewed as a normalization constant alpha
 	P(Cavity|toothache) = alpha * P(Cavity,toothache)
 -general idea: compute distribution on query variable by fixing evidence variables and summing over hidden variables
 	slide 17 with 1:31:30 left in lecture


 	Independence
 	A and B are independent iff

 	P(A|B) = P(A) or P(B|A) = P(B) or P(A,B) = P(A)*P(B)

 	P(Toothache,Catch,Cavity,Weather)
 	=P(Toothache,Catch,Cavity)P(Weather)

 -32 entries reduced to 12; for n independent biased coins, O(2^n)->O(n)
 -absolute independence powerful but rare
 -dentistry is a large field with hundreds of variables, none of which are independent What to do?

 	Cavity 		decomposes to      Cavity,Toothache,
 	Toothache   ------------>      Catch
 	Catch
 	Weather 						Weather

Bayes' Rule
	P(a|b) = p(b|a)*P(a)/P(b)

	or in distribution form
		P(Y|X) = P(X|Y)*P(Y)/P(X) = alpha*P(X|Y)*P(Y)
		P(Y|X,e) = P(X|Y,e)*P(Y|e)
				   _______________
				      P(X|e)

	P(Cause|Effect) = P(Effect|Cause)*P(Cause)/P(Effect)

	Bayes' Rule and Conditional Independence
	P(Cavity|toothache^catch) = alpha<.108,.016> = <.871,.129>

P(Toothache,Cavity,Catch) has 2^3 -1 = 7 independent entries

if I have a cavity the probability that the probe catches in it doesn't depend on whether I have a toothache

Wumpus World
P_ij = true iff [i,j] contains a pit
B_ij = true iff [i,j] is breezy
-include only B11,B12,B21 in the probability model

Specifying the Probability model
-the probability there is a pit = .2^n * .8^16
for n pits

Observation and Query
-We know the following facts:
	b = not b_11 ^ b_12 ^ b_21
	known = not p_11 ^ not p_12 ^ not p_21

Query is P(P_14|known,b)

Using conditional independence
-basic insight: observations are conditionally independent of other hidden squares given neighboring hidden squares
-Define Unknown = Fringe U Other


-------------------------------------------------------

Artificial Intelligence Lecture 14 Notes


Probabilistic Reasoning

Bayesian Networks
-a simple graphical notation for conditional independence assertions and hence for compact specificataion of full joint
-syntax
	-a set of nodes, one per variable
	- a directed acyclic graph( link ~ directly influences)
	-a conditional distribution for each node give its parents 
		P(Xi | PArents (Xi))
-in the simplest case, conditional distribution represented as a conditional probability table (CPT) giving the distribution Xi for each combination of parent values

Ex:
	-Topology of network encodes conditional independence
	-weather is independent of the other variables
	-Toothache and Catch are conditionally independent given Cavity

Ex: 
	Im at work, neighbor John calls to say my alarm is ringing, but neighbor Mary doesn't call. Sometimes its set off by minor earthquaekes.  Is there a burglar?
-variables
	Burglary, Earthquake, Alarm, JohnCalls, MaryCalls
-network topology reflects "causal" knowledge
	-A burglar can set the alarm off
	-an earthquake can set the alarm off
	-the alarm can cause Mary to call
	-the alarm can cause John to call
-each node has 2^(# of parents) entries in their probability topology table

p(a | b,e) = 1-P(not a | b,e)


Compactness
-a CPT fr Boolena Xi with k boolean parents has 2^k rows for the combinations of parent values
-each row requires one number p for Xi=true
-if each variable has no more than k parents, the complete network requires O(n*2^k)

Global Semantics
-the full joint distribution is defined as the product of the local conditional distributions
P(x1,...,xn) = Prodi=1..n o fP(xi|Parents(Xi))

e.g.

P(j^m^a^not b^not e)
=P(j|a)*P(m|a)*P(a|notb,note)*P(notb)*P(not e)
= .9 x .7 x .001 x .999 x .998
~ .00063

if it had been not a in the left side then not a would have been at every spot instead of a on the right side

Local Semantics
-each node is conditionally independento fits non-descendants given its parents
-Thm: local semantics <=> global semantics

MArkov blanket
-each node is conditionally independent of all others given its Markov blanket
	-PArents + children + children's parents

be able to determine Markov blanket for final



Learning
-learning is essential for unknown environments 
	-when designer lacks omniscience
-learning is useful as a system construction method
	-i.e. expose the agent to reality rather than trying to write it down
-learning modifies the agent's decision mechanisms to improve performance

Learning AGents 
-they learn so that they can perform better

Learning element
-design of a learning element is affected by:
	-what type of performance element is used 
	-which (functinoal) component(s) of the performance element is (are) to be learned
	-what representation is used for the learned information
	--what kind of feedback is available to learn thesee componenets
	-the availability of prior knowledge
-type of feedback defines 3 major paradigms
	-supervise learning
		-correct answers for each example
	-unsupervised learning
		-correct answers not given
	-reinforcement learning
		-occasional rewards

reinforcement

supervised ex:
inductive learning
-simplest form: learn a function from examples
f is a target fucntion
an example is a pair (x,f(x))

Problem: find a hypothesis h
	s.t. h ~f
	given a training set of examples
-Note: This is a highly simplified model of real learning:
	-ignores prior knowledge
	-assumes a deterministic, observable "environment"
	-assumes examples are given
	-assumes taht the agent wants to learn f w.o. caring why it wants to learn f

ex. of inductive learning
	-curve fitting
	-construct/adjust h to agree with f on training set
	-h is consistent if it agrees with f on ALL examples

	Ockham's razor:
	-always take simplest route

Learning Decision Trees

Decision Tree
-one possible representation for hypothesis
-E.g. here is the "true" tree for deciding whether to wait:

Problem: decide whether to wait for a table at a restaurant, based on the following attribtues
.
.
.
.
Goal: learn the goal predicate WillWait

Attribute based represntation
-sample data with result
-classification problem on if willwait

expressiveness
-decision trees can express any Boolean function
-E.g. for Boolean functinons, truth table row-> path to leaf


Hypothesis Spaces
-how many distinct decision trees we n boolean attributes
2^(2^n) with n = number of boolean attributes

End of Class -----------------------------------------






























├i












































